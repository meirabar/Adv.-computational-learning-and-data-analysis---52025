<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>PS3_Attention_Please_2024_ID_209307396</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                messageStyle: 'none',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Neural-Machine-Translation-with-Attention">Neural Machine Translation with Attention<a class="anchor-link" href="#Neural-Machine-Translation-with-Attention">¶</a></h1><p>Advanced Learning Fall 2024.<br/>
Last updated: 2025-01-12</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>For SUBMISSION:</p>
<p>Please upload the complete and executed <code>ipynb</code> to your git repository. Verify that all of your output can be viewed directly from github, and provide a link to that git file below.</p>
<pre><code>STUDENT ID: 209307396
</code></pre>
<pre><code>STUDENT GIT LINK: https://github.com/meirabar/Adv.-computational-learning-and-data-analysis---52025.git
</code></pre>
<p>In Addition, don't forget to add your ID to the files, and upload to moodle the html version:</p>
<p><code>PS3_Attention_2024_ID_[209307396].html</code></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>In this problem set we are going to jump into the depths of <code>seq2seq</code> and <code>attention</code> and build a couple of PyTorch translation mechanisms with some  twists.</p>
<ul>
<li>Part 1 consists of a somewhat unorthodox <code>seq2seq</code> model for simple arithmetics</li>
<li>Part 2 consists of an <code>seq2seq - attention</code> language translation model. We will use it for Hebrew and English.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>A <strong>seq2seq</strong> model (sequence-to-sequence model) is a type of neural network designed specifically to handle sequences of data. The model converts input sequences into other sequences of data. This makes them particularly useful for tasks involving language, where the input and output are naturally sequences of words.</p>
<p>Here's a breakdown of how <code>seq2seq</code> models work:</p>
<ul>
<li><p>The encoder takes the input sequence, like a sentence in English, and processes it to capture its meaning and context.</p>
</li>
<li><p>information is then passed to the decoder, which uses it to generate the output sequence, like a translation in French.</p>
</li>
<li><p>Attention mechanism (optional): Some <code>seq2seq</code> models also incorporate an attention mechanism. This allows the decoder to focus on specific parts of the input sequence that are most relevant to generating the next element in the output sequence.</p>
</li>
</ul>
<p><code>seq2seq</code> models are used in many natural language processing (NLP) tasks.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>imports: (feel free to add)</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># from __future__ import unicode_literals, print_function, division</span>
<span class="c1"># from io import open</span>
<span class="c1"># import unicodedata</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-1:-Seq2Seq-Arithmetic-model">Part 1: Seq2Seq Arithmetic model<a class="anchor-link" href="#Part-1:-Seq2Seq-Arithmetic-model">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Using RNN <code>seq2seq</code> model to "learn" simple arithmetics!</strong></p>
<blockquote>
<p>Given the string "54-7", the model should return a prediction: "47".<br/>
Given the string "10+20", the model should return a prediction: "30".</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>Watch Lukas Biewald's short <a href="https://youtu.be/MqugtGD605k?si=rAH34ZTJyYDj-XJ1">video</a> explaining <code>seq2seq</code> models and his toy application (somewhat outdated).</li>
<li>You can find the code for his example <a href="https://github.com/lukas/ml-class/blob/master/videos/seq2seq/train.py">here</a>.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.1) Using Lukas' code, implement a <code>seq2seq</code> network that can learn how to solve <strong>addition AND substraction</strong> of two numbers of maximum length of 4, using the following steps (similar to the example):</p>
<ul>
<li>Generate data; X: queries (two numbers), and Y: answers</li>
<li>One-hot encode X and Y,</li>
<li>Build a <code>seq2seq</code> network (with LSTM, RepeatVector, and TimeDistributed layers)</li>
<li>Train the model.</li>
<li>While training, sample from the validation set at random so we can visualize the generated solutions against the true solutions.</li>
</ul>
<p>Notes:</p>
<ul>
<li>The code in the example is quite old and based on Keras. You might have to adapt some of the code to overcome methods/code that is not supported anymore. Hint: for the evaluation part, review the type and format of the "correct" output - this will help you fix the unsupported "model.predict_classes".</li>
<li>Please use the parameters in the code cell below to train the model.</li>
<li>Instead of using a <code>wandb.config</code> object, please use a simple dictionary instead.</li>
<li>You don't need to run the model for more than 50 iterations (epochs) to get a gist of what is happening and what the algorithm is doing.</li>
<li>Extra credit if you can implement the network in PyTorch (this is not difficult).</li>
<li>Extra credit if you are able to significantly improve the model.</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Attention</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">RepeatVector</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">Layer</span><span class="p">,</span> <span class="n">Concatenate</span>


<span class="k">class</span> <span class="nc">CharacterTable</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chars</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">char_indices</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">indices_char</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_rows</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_indices</span><span class="p">[</span><span class="n">c</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">calc_argmax</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">calc_argmax</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">indices_char</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x</span><span class="p">)</span>

<span class="c1"># Configuration parameters</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"training_size"</span><span class="p">:</span> <span class="mi">40000</span><span class="p">,</span>
    <span class="s2">"digits"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">"hidden_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"iterations"</span><span class="p">:</span> <span class="mi">50</span>
<span class="p">}</span>

<span class="c1"># Define character set and maximum length</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s1">'0123456789-+ '</span>
<span class="n">maxlen</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span>
<span class="n">ctable</span> <span class="o">=</span> <span class="n">CharacterTable</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

<span class="c1"># Generate training data</span>
<span class="n">questions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Generating data...'</span><span class="p">)</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="s1">'0123456789'</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))))</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">f</span><span class="p">(),</span> <span class="n">f</span><span class="p">()</span>
    <span class="n">key</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">sorted</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)))</span>
    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="s1">'</span><span class="si">{}</span><span class="s1">-</span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">q</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">*</span> <span class="p">(</span><span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>
    <span class="n">ans</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">ans</span> <span class="o">+=</span> <span class="s1">' '</span> <span class="o">*</span> <span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">ans</span><span class="p">))</span>

    <span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">expected</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Total subtraction questions:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">))</span>

<span class="c1"># Vectorize the data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Vectorization...'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">maxlen</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">questions</span><span class="p">):</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">expected</span><span class="p">):</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Shuffle the data</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

<span class="c1"># Split into training and validation sets</span>
<span class="n">split_at</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_val</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>
<span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>

<span class="c1"># Build the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">LSTM</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">))),</span>
    <span class="n">RepeatVector</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">LSTM</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># Training loop with updated prediction handling</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Iteration'</span><span class="p">,</span> <span class="n">iteration</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
             <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span>
             <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
             <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>

    <span class="c1"># Validate on 10 random samples</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span>
        <span class="n">rowx</span><span class="p">,</span> <span class="n">rowy</span> <span class="o">=</span> <span class="n">x_val</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ind</span><span class="p">])],</span> <span class="n">y_val</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ind</span><span class="p">])]</span>

        <span class="c1"># Updated prediction handling - using argmax on the raw predictions</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">rowx</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">pred_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">rowx</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">rowy</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">guess</span> <span class="o">=</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ctable</span><span class="o">.</span><span class="n">indices_char</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pred_classes</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">'Q:'</span><span class="p">,</span> <span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'T:'</span><span class="p">,</span> <span class="n">correct</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">correct</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="n">guess</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'☑'</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'☒'</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">guess</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Generating data...
Total subtraction questions: 40000
Vectorization...
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential"</span>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                         </span>┃<span style="font-weight: bold"> Output Shape                </span>┃<span style="font-weight: bold">         Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm (<span style="color: #0087ff; text-decoration-color: #0087ff">LSTM</span>)                          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)                 │          <span style="color: #00af00; text-decoration-color: #00af00">72,704</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ repeat_vector (<span style="color: #0087ff; text-decoration-color: #0087ff">RepeatVector</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)              │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">LSTM</span>)                        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)              │         <span style="color: #00af00; text-decoration-color: #00af00">131,584</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ time_distributed (<span style="color: #0087ff; text-decoration-color: #0087ff">TimeDistributed</span>)   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>)               │           <span style="color: #00af00; text-decoration-color: #00af00">1,677</span> │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">205,965</span> (804.55 KB)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">205,965</span> (804.55 KB)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
--------------------------------------------------
Iteration 1
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">8s</span> 9ms/step - accuracy: 0.2862 - loss: 2.1107 - val_accuracy: 0.3880 - val_loss: 1.6632
Q: 3370-6 T: 3364 ☒ 669
Q: 5-765 T: -760 ☒ -55
Q: 937-33 T: 904 ☒ 25
Q: 18-51 T: -33 ☒ -1
Q: 1171-985 T: 186 ☒ -76
Q: 8226-8 T: 8218 ☒ 6699
Q: 2277-194 T: 2083 ☒ 176
Q: 923-328 T: 595 ☒ -23
Q: 3050-2 T: 3048 ☒ 669
Q: 667-22 T: 645 ☒ 15

--------------------------------------------------
Iteration 2
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 11ms/step - accuracy: 0.4010 - loss: 1.6302 - val_accuracy: 0.4196 - val_loss: 1.5818
Q: 351-0 T: 351 ☒ 311
Q: 7378-3999 T: 3379 ☒ -771
Q: 305-7943 T: -7638 ☒ -3911
Q: 6415-2493 T: 3922 ☒ -111
Q: 612-1112 T: -500 ☒ -111
Q: 77-3424 T: -3347 ☒ -2216
Q: 824-6 T: 818 ☒ 877
Q: 388-1 T: 387 ☒ 887
Q: 772-48 T: 724 ☒ 777
Q: 4-510 T: -506 ☒ -41

--------------------------------------------------
Iteration 3
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.4308 - loss: 1.5495 - val_accuracy: 0.4438 - val_loss: 1.4984
Q: 443-6 T: 437 ☒ 440
Q: 557-918 T: -361 ☒ -50
Q: 4898-37 T: 4861 ☒ 8877
Q: 6567-189 T: 6378 ☒ 6602
Q: 1677-251 T: 1426 ☒ 111
Q: 929-57 T: 872 ☒ 999
Q: 932-9925 T: -8993 ☒ -9905
Q: 255-8 T: 247 ☒ 552
Q: 800-350 T: 450 ☒ 110
Q: 1780-5 T: 1775 ☒ 777

--------------------------------------------------
Iteration 4
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.4520 - loss: 1.4719 - val_accuracy: 0.4639 - val_loss: 1.4379
Q: 538-7604 T: -7066 ☒ -7477
Q: 9485-33 T: 9452 ☒ 9988
Q: 5051-44 T: 5007 ☒ 5443
Q: 2-23 T: -21 ☒ -28
Q: 346-1833 T: -1487 ☒ -3077
Q: 84-615 T: -531 ☒ -443
Q: 9036-4 T: 9032 ☒ 9999
Q: 36-47 T: -11 ☒ -44
Q: 44-968 T: -924 ☒ -888
Q: 97-7214 T: -7117 ☒ -7277

--------------------------------------------------
Iteration 5
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 7ms/step - accuracy: 0.4783 - loss: 1.3933 - val_accuracy: 0.4963 - val_loss: 1.3359
Q: 8222-8546 T: -324 ☒ 221
Q: 95-40 T: 55 ☒ 44
Q: 4081-2363 T: 1718 ☒ 310
Q: 362-947 T: -585 ☒ -323
Q: 77-6 T: 71 ☒ 63
Q: 719-46 T: 673 ☒ 733
Q: 98-91 T: 7 ☒ 8
Q: 7008-9954 T: -2946 ☒ -133
Q: 73-2 T: 71 ☒ 77
Q: 3760-530 T: 3230 ☒ 3113

--------------------------------------------------
Iteration 6
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 7ms/step - accuracy: 0.5130 - loss: 1.3100 - val_accuracy: 0.5304 - val_loss: 1.2552
Q: 5883-89 T: 5794 ☒ 8886
Q: 91-1302 T: -1211 ☒ -1044
Q: 1886-255 T: 1631 ☒ 1666
Q: 4-9355 T: -9351 ☒ -9433
Q: 4-5460 T: -5456 ☒ -4400
Q: 5668-55 T: 5613 ☒ 5556
Q: 8356-3 T: 8353 ☒ 8226
Q: 3-3059 T: -3056 ☒ -3003
Q: 885-4 T: 881 ☒ 886
Q: 481-51 T: 430 ☒ 476

--------------------------------------------------
Iteration 7
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.5386 - loss: 1.2424 - val_accuracy: 0.5485 - val_loss: 1.2139
Q: 617-924 T: -307 ☒ -584
Q: 5546-1 T: 5545 ☒ 5518
Q: 1226-32 T: 1194 ☒ 1188
Q: 5030-89 T: 4941 ☒ 5088
Q: 4-4176 T: -4172 ☒ -4110
Q: 505-59 T: 446 ☒ 408
Q: 37-98 T: -61 ☒ -55
Q: 7-5874 T: -5867 ☒ -5750
Q: 647-46 T: 601 ☒ 638
Q: 4274-326 T: 3948 ☒ 3888

--------------------------------------------------
Iteration 8
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 7ms/step - accuracy: 0.5615 - loss: 1.1816 - val_accuracy: 0.5705 - val_loss: 1.1558
Q: 373-3 T: 370 ☑ 370
Q: 590-9 T: 581 ☒ 595
Q: 48-2703 T: -2655 ☒ -2790
Q: 4-399 T: -395 ☒ -397
Q: 7-543 T: -536 ☒ -545
Q: 7454-83 T: 7371 ☒ 7411
Q: 7465-1 T: 7464 ☒ 7470
Q: 84-766 T: -682 ☒ -650
Q: 6180-8 T: 6172 ☒ 6000
Q: 9854-749 T: 9105 ☒ 8033

--------------------------------------------------
Iteration 9
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 7ms/step - accuracy: 0.5787 - loss: 1.1365 - val_accuracy: 0.5889 - val_loss: 1.1059
Q: 36-684 T: -648 ☒ -635
Q: 8990-656 T: 8334 ☒ 8043
Q: 2440-896 T: 1544 ☒ 2455
Q: 37-109 T: -72 ☒ -10
Q: 5659-0 T: 5659 ☒ 5685
Q: 356-6 T: 350 ☒ 352
Q: 5099-77 T: 5022 ☒ 5043
Q: 796-87 T: 709 ☒ 704
Q: 558-933 T: -375 ☒ -374
Q: 44-992 T: -948 ☒ -944

--------------------------------------------------
Iteration 10
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.5927 - loss: 1.0957 - val_accuracy: 0.5929 - val_loss: 1.0827
Q: 6-976 T: -970 ☒ -962
Q: 517-7 T: 510 ☒ 516
Q: 91-44 T: 47 ☒ 41
Q: 61-1617 T: -1556 ☒ -1501
Q: 45-28 T: 17 ☒ 2
Q: 315-569 T: -254 ☒ -222
Q: 35-36 T: -1 ☒ -
Q: 7-3687 T: -3680 ☒ -3676
Q: 40-924 T: -884 ☒ -894
Q: 63-808 T: -745 ☒ -782

--------------------------------------------------
Iteration 11
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.6061 - loss: 1.0597 - val_accuracy: 0.6062 - val_loss: 1.0603
Q: 912-3 T: 909 ☒ 906
Q: 5-9785 T: -9780 ☒ -9768
Q: 7826-5 T: 7821 ☒ 7828
Q: 69-9001 T: -8932 ☒ -8994
Q: 448-94 T: 354 ☒ 365
Q: 3-7610 T: -7607 ☒ -7608
Q: 40-326 T: -286 ☒ -296
Q: 1725-42 T: 1683 ☒ 1698
Q: 5567-148 T: 5419 ☒ 5466
Q: 820-158 T: 662 ☒ 666

--------------------------------------------------
Iteration 12
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6172 - loss: 1.0328 - val_accuracy: 0.6042 - val_loss: 1.0482
Q: 9459-15 T: 9444 ☒ 9451
Q: 170-907 T: -737 ☒ -690
Q: 6716-766 T: 5950 ☒ 6099
Q: 931-66 T: 865 ☒ 898
Q: 8-4375 T: -4367 ☒ -4365
Q: 34-7215 T: -7181 ☒ -7199
Q: 328-2263 T: -1935 ☒ -1954
Q: 1873-7866 T: -5993 ☒ -6990
Q: 32-52 T: -20 ☒ -19
Q: 6116-7 T: 6109 ☒ 6150

--------------------------------------------------
Iteration 13
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6259 - loss: 1.0030 - val_accuracy: 0.6259 - val_loss: 0.9996
Q: 9534-74 T: 9460 ☑ 9460
Q: 1906-1849 T: 57 ☒ 102
Q: 4-238 T: -234 ☒ -233
Q: 6-3204 T: -3198 ☒ -3204
Q: 755-720 T: 35 ☒ -5
Q: 921-476 T: 445 ☒ 362
Q: 309-880 T: -571 ☒ -580
Q: 7455-74 T: 7381 ☒ 7388
Q: 6298-6 T: 6292 ☒ 6283
Q: 732-1125 T: -393 ☒ -45

--------------------------------------------------
Iteration 14
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">4s</span> 13ms/step - accuracy: 0.6369 - loss: 0.9770 - val_accuracy: 0.6247 - val_loss: 0.9939
Q: 99-762 T: -663 ☒ -634
Q: 5-6088 T: -6083 ☒ -6078
Q: 812-98 T: 714 ☒ 735
Q: 2630-2 T: 2628 ☒ 2626
Q: 719-0 T: 719 ☒ 706
Q: 42-8725 T: -8683 ☒ -8678
Q: 6-683 T: -677 ☒ -674
Q: 321-3798 T: -3477 ☒ -3544
Q: 4-5045 T: -5041 ☒ -504
Q: 1307-855 T: 452 ☒ 732

--------------------------------------------------
Iteration 15
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 11ms/step - accuracy: 0.6475 - loss: 0.9519 - val_accuracy: 0.6315 - val_loss: 0.9742
Q: 1-7442 T: -7441 ☒ -7440
Q: 952-33 T: 919 ☒ 911
Q: 52-698 T: -646 ☒ -631
Q: 96-68 T: 28 ☒ 11
Q: 8003-7 T: 7996 ☒ 8001
Q: 3537-599 T: 2938 ☒ 3161
Q: 17-102 T: -85 ☒ -92
Q: 43-1894 T: -1851 ☒ -1852
Q: 1-8667 T: -8666 ☒ -8665
Q: 9-833 T: -824 ☒ -828

--------------------------------------------------
Iteration 16
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 7ms/step - accuracy: 0.6547 - loss: 0.9298 - val_accuracy: 0.6517 - val_loss: 0.9282
Q: 52-4120 T: -4068 ☒ -4079
Q: 3962-74 T: 3888 ☒ 3813
Q: 98-474 T: -376 ☒ -363
Q: 0-5245 T: -5245 ☒ -5241
Q: 372-23 T: 349 ☒ 353
Q: 5108-6 T: 5102 ☒ 5006
Q: 887-7 T: 880 ☒ 870
Q: 270-9071 T: -8801 ☒ -8911
Q: 4-723 T: -719 ☒ -729
Q: 4060-7029 T: -2969 ☒ -2110

--------------------------------------------------
Iteration 17
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">4s</span> 13ms/step - accuracy: 0.6641 - loss: 0.9029 - val_accuracy: 0.6557 - val_loss: 0.9150
Q: 3446-144 T: 3302 ☒ 3300
Q: 2588-1158 T: 1430 ☒ 1377
Q: 131-3586 T: -3455 ☒ -3444
Q: 143-204 T: -61 ☒ -91
Q: 611-90 T: 521 ☒ 510
Q: 113-67 T: 46 ☒ 64
Q: 628-9 T: 619 ☒ 614
Q: 9116-6 T: 9110 ☒ 9163
Q: 12-442 T: -430 ☒ -429
Q: 9044-2118 T: 6926 ☒ 7811

--------------------------------------------------
Iteration 18
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">4s</span> 15ms/step - accuracy: 0.6692 - loss: 0.8889 - val_accuracy: 0.6601 - val_loss: 0.8968
Q: 7465-1 T: 7464 ☒ 7453
Q: 998-127 T: 871 ☒ 966
Q: 3-7610 T: -7607 ☒ -7609
Q: 5051-44 T: 5007 ☒ 5099
Q: 205-734 T: -529 ☒ -566
Q: 57-2565 T: -2508 ☒ -2500
Q: 841-3 T: 838 ☒ 839
Q: 4558-670 T: 3888 ☒ 3879
Q: 5659-0 T: 5659 ☒ 5656
Q: 255-8 T: 247 ☒ 248

--------------------------------------------------
Iteration 19
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">6s</span> 20ms/step - accuracy: 0.6776 - loss: 0.8642 - val_accuracy: 0.6598 - val_loss: 0.8907
Q: 886-9 T: 877 ☒ 876
Q: 6724-70 T: 6654 ☒ 6666
Q: 56-91 T: -35 ☑ -35
Q: 18-378 T: -360 ☒ -369
Q: 53-712 T: -659 ☒ -660
Q: 11-29 T: -18 ☒ -17
Q: 9255-874 T: 8381 ☒ 8860
Q: 0-696 T: -696 ☒ -695
Q: 8-974 T: -966 ☑ -966
Q: 7976-293 T: 7683 ☒ 7586

--------------------------------------------------
Iteration 20
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6866 - loss: 0.8399 - val_accuracy: 0.6715 - val_loss: 0.8731
Q: 4-8061 T: -8057 ☒ -8055
Q: 6-9733 T: -9727 ☒ -9733
Q: 1028-24 T: 1004 ☒ 1014
Q: 8658-3777 T: 4881 ☒ 5099
Q: 98-91 T: 7 ☒ -
Q: 5-2296 T: -2291 ☒ -2292
Q: 3241-668 T: 2573 ☒ 2655
Q: 2948-8332 T: -5384 ☒ -5955
Q: 796-607 T: 189 ☒ 135
Q: 2075-8 T: 2067 ☒ 2077

--------------------------------------------------
Iteration 21
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6917 - loss: 0.8249 - val_accuracy: 0.6703 - val_loss: 0.8593
Q: 638-6 T: 632 ☒ 635
Q: 326-8 T: 318 ☒ 327
Q: 6-50 T: -44 ☑ -44
Q: 9080-808 T: 8272 ☒ 8900
Q: 22-2937 T: -2915 ☒ -2943
Q: 163-9 T: 154 ☒ 157
Q: 1906-1849 T: 57 ☒ 125
Q: 472-137 T: 335 ☒ 433
Q: 854-9 T: 845 ☒ 856
Q: 9-5771 T: -5762 ☒ -5768

--------------------------------------------------
Iteration 22
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.6987 - loss: 0.8031 - val_accuracy: 0.6779 - val_loss: 0.8430
Q: 7-1815 T: -1808 ☒ -1856
Q: 5874-6 T: 5868 ☒ 5840
Q: 8371-4 T: 8367 ☒ 8366
Q: 415-167 T: 248 ☒ 262
Q: 609-539 T: 70 ☒ 12
Q: 2-7418 T: -7416 ☒ -7418
Q: 559-5669 T: -5110 ☒ -5000
Q: 9162-24 T: 9138 ☒ 9119
Q: 3343-225 T: 3118 ☒ 3100
Q: 31-415 T: -384 ☒ -389

--------------------------------------------------
Iteration 23
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7062 - loss: 0.7860 - val_accuracy: 0.6896 - val_loss: 0.8152
Q: 862-5 T: 857 ☒ 856
Q: 184-442 T: -258 ☒ -366
Q: 824-502 T: 322 ☒ 369
Q: 221-9185 T: -8964 ☒ -8055
Q: 22-459 T: -437 ☒ -444
Q: 6963-4763 T: 2200 ☒ 2099
Q: 88-186 T: -98 ☒ -10
Q: 5051-44 T: 5007 ☒ 5099
Q: 4489-243 T: 4246 ☒ 4244
Q: 5962-3500 T: 2462 ☒ 2464

--------------------------------------------------
Iteration 24
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7159 - loss: 0.7594 - val_accuracy: 0.6896 - val_loss: 0.7987
Q: 82-31 T: 51 ☒ 50
Q: 647-46 T: 601 ☒ 611
Q: 2546-1533 T: 1013 ☒ 127
Q: 30-513 T: -483 ☒ -470
Q: 741-445 T: 296 ☒ 372
Q: 548-884 T: -336 ☑ -336
Q: 8650-984 T: 7666 ☒ 7755
Q: 5-102 T: -97 ☒ -90
Q: 3-51 T: -48 ☒ -47
Q: 4898-37 T: 4861 ☒ 4852

--------------------------------------------------
Iteration 25
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 9ms/step - accuracy: 0.7202 - loss: 0.7446 - val_accuracy: 0.7022 - val_loss: 0.7755
Q: 5001-276 T: 4725 ☒ 4544
Q: 2656-4161 T: -1505 ☒ -154
Q: 788-342 T: 446 ☒ 445
Q: 27-919 T: -892 ☒ -885
Q: 26-245 T: -219 ☒ -218
Q: 94-31 T: 63 ☑ 63
Q: 51-56 T: -5 ☒ -4
Q: 9-7928 T: -7919 ☒ -7910
Q: 1237-726 T: 511 ☒ 665
Q: 5071-837 T: 4234 ☒ 4235

--------------------------------------------------
Iteration 26
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7287 - loss: 0.7228 - val_accuracy: 0.7013 - val_loss: 0.7782
Q: 336-0 T: 336 ☑ 336
Q: 71-1602 T: -1531 ☒ -1551
Q: 9-6891 T: -6882 ☒ -6889
Q: 51-70 T: -19 ☒ -10
Q: 2760-6 T: 2754 ☒ 2753
Q: 369-9121 T: -8752 ☒ -8777
Q: 115-7 T: 108 ☑ 108
Q: 908-18 T: 890 ☒ 898
Q: 1-3685 T: -3684 ☒ -3674
Q: 151-5 T: 146 ☒ 147

--------------------------------------------------
Iteration 27
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7353 - loss: 0.7069 - val_accuracy: 0.7103 - val_loss: 0.7493
Q: 455-2603 T: -2148 ☒ -2364
Q: 188-218 T: -30 ☒ -88
Q: 8-6034 T: -6026 ☑ -6026
Q: 5449-265 T: 5184 ☒ 5174
Q: 5-1104 T: -1099 ☒ -1011
Q: 5883-89 T: 5794 ☒ 5795
Q: 8233-948 T: 7285 ☒ 7455
Q: 2-933 T: -931 ☑ -931
Q: 78-1389 T: -1311 ☒ -1310
Q: 3251-4078 T: -827 ☒ -1444

--------------------------------------------------
Iteration 28
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 7ms/step - accuracy: 0.7400 - loss: 0.6893 - val_accuracy: 0.7130 - val_loss: 0.7375
Q: 3704-0 T: 3704 ☒ 3703
Q: 74-241 T: -167 ☒ -155
Q: 0-7158 T: -7158 ☒ -7177
Q: 9744-5 T: 9739 ☒ 9740
Q: 606-84 T: 522 ☑ 522
Q: 693-3247 T: -2554 ☒ -2653
Q: 9901-7 T: 9894 ☑ 9894
Q: 4740-5628 T: -888 ☒ -1898
Q: 1-7442 T: -7441 ☒ -7440
Q: 5785-4908 T: 877 ☒ -10

--------------------------------------------------
Iteration 29
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.7497 - loss: 0.6662 - val_accuracy: 0.7262 - val_loss: 0.7023
Q: 8-81 T: -73 ☑ -73
Q: 570-474 T: 96 ☒ 124
Q: 74-7261 T: -7187 ☒ -7104
Q: 6467-467 T: 6000 ☒ 5000
Q: 5-903 T: -898 ☑ -898
Q: 64-1356 T: -1292 ☒ -1280
Q: 8630-192 T: 8438 ☒ 8432
Q: 75-611 T: -536 ☒ -544
Q: 4-4176 T: -4172 ☑ -4172
Q: 717-242 T: 475 ☒ 477

--------------------------------------------------
Iteration 30
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.7563 - loss: 0.6455 - val_accuracy: 0.7277 - val_loss: 0.6921
Q: 330-56 T: 274 ☒ 265
Q: 45-250 T: -205 ☒ -206
Q: 5768-607 T: 5161 ☒ 5999
Q: 30-88 T: -58 ☒ -68
Q: 2911-6 T: 2905 ☒ 2916
Q: 7089-5 T: 7084 ☒ 7074
Q: 60-265 T: -205 ☒ -215
Q: 1767-62 T: 1705 ☒ 1613
Q: 7868-77 T: 7791 ☒ 7899
Q: 186-4149 T: -3963 ☒ -4957

--------------------------------------------------
Iteration 31
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 9ms/step - accuracy: 0.7662 - loss: 0.6223 - val_accuracy: 0.7394 - val_loss: 0.6752
Q: 92-97 T: -5 ☒ -14
Q: 5668-55 T: 5613 ☑ 5613
Q: 562-887 T: -325 ☒ -336
Q: 82-567 T: -485 ☒ -484
Q: 42-93 T: -51 ☒ -40
Q: 73-389 T: -316 ☒ -325
Q: 68-204 T: -136 ☒ -144
Q: 3977-6 T: 3971 ☒ 3972
Q: 169-64 T: 105 ☒ 12
Q: 606-71 T: 535 ☒ 545

--------------------------------------------------
Iteration 32
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7718 - loss: 0.6069 - val_accuracy: 0.7417 - val_loss: 0.6613
Q: 686-79 T: 607 ☒ 697
Q: 906-3361 T: -2455 ☒ -2664
Q: 41-805 T: -764 ☒ -765
Q: 984-843 T: 141 ☒ 110
Q: 3-3059 T: -3056 ☒ -3055
Q: 822-7181 T: -6359 ☒ -6278
Q: 885-4 T: 881 ☑ 881
Q: 279-843 T: -564 ☒ -565
Q: 34-5 T: 29 ☒ 28
Q: 0-8444 T: -8444 ☑ -8444

--------------------------------------------------
Iteration 33
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.7808 - loss: 0.5859 - val_accuracy: 0.7484 - val_loss: 0.6440
Q: 15-51 T: -36 ☑ -36
Q: 824-502 T: 322 ☒ 321
Q: 34-4015 T: -3981 ☒ -3980
Q: 2-487 T: -485 ☑ -485
Q: 252-6 T: 246 ☒ 247
Q: 5172-20 T: 5152 ☒ 5263
Q: 6-5695 T: -5689 ☑ -5689
Q: 194-896 T: -702 ☒ -700
Q: 81-8664 T: -8583 ☒ -8694
Q: 9-9255 T: -9246 ☒ -9247

--------------------------------------------------
Iteration 34
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7883 - loss: 0.5686 - val_accuracy: 0.7614 - val_loss: 0.6179
Q: 2-6661 T: -6659 ☑ -6659
Q: 8578-60 T: 8518 ☒ 8491
Q: 6487-16 T: 6471 ☒ 6470
Q: 1-122 T: -121 ☒ -122
Q: 8401-7 T: 8394 ☒ 8393
Q: 5-1104 T: -1099 ☒ -1011
Q: 4798-399 T: 4399 ☒ 4400
Q: 65-72 T: -7 ☒ -8
Q: 3690-4 T: 3686 ☒ 3685
Q: 840-4633 T: -3793 ☒ -3729

--------------------------------------------------
Iteration 35
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 11ms/step - accuracy: 0.7979 - loss: 0.5460 - val_accuracy: 0.7686 - val_loss: 0.6053
Q: 9-48 T: -39 ☒ -49
Q: 45-1289 T: -1244 ☒ -1243
Q: 13-1223 T: -1210 ☒ -1209
Q: 87-248 T: -161 ☑ -161
Q: 631-54 T: 577 ☑ 577
Q: 8162-33 T: 8129 ☒ 8110
Q: 5091-6 T: 5085 ☒ 5065
Q: 27-916 T: -889 ☒ -888
Q: 115-7 T: 108 ☑ 108
Q: 3029-1 T: 3028 ☒ 3008

--------------------------------------------------
Iteration 36
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8040 - loss: 0.5313 - val_accuracy: 0.7650 - val_loss: 0.6036
Q: 6708-67 T: 6641 ☒ 6642
Q: 7738-32 T: 7706 ☒ 7616
Q: 128-528 T: -400 ☒ -490
Q: 53-16 T: 37 ☑ 37
Q: 76-24 T: 52 ☑ 52
Q: 2299-147 T: 2152 ☒ 2208
Q: 588-85 T: 503 ☒ 403
Q: 8-2609 T: -2601 ☒ -2691
Q: 473-562 T: -89 ☒ -18
Q: 6-50 T: -44 ☑ -44

--------------------------------------------------
Iteration 37
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8142 - loss: 0.5091 - val_accuracy: 0.7784 - val_loss: 0.5747
Q: 68-6558 T: -6490 ☑ -6490
Q: 953-7 T: 946 ☑ 946
Q: 219-2028 T: -1809 ☒ -1900
Q: 7581-7407 T: 174 ☒ 152
Q: 0-414 T: -414 ☑ -414
Q: 4-2466 T: -2462 ☒ -2562
Q: 95-94 T: 1 ☒ 0
Q: 8866-0 T: 8866 ☒ 8864
Q: 866-300 T: 566 ☒ 577
Q: 18-3925 T: -3907 ☒ -3917

--------------------------------------------------
Iteration 38
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8174 - loss: 0.4967 - val_accuracy: 0.7819 - val_loss: 0.5655
Q: 88-73 T: 15 ☒ 25
Q: 160-553 T: -393 ☒ -333
Q: 330-56 T: 274 ☒ 264
Q: 635-1 T: 634 ☑ 634
Q: 49-821 T: -772 ☑ -772
Q: 17-48 T: -31 ☒ -30
Q: 986-77 T: 909 ☒ 919
Q: 16-179 T: -163 ☑ -163
Q: 820-158 T: 662 ☒ 643
Q: 63-57 T: 6 ☒ 4

--------------------------------------------------
Iteration 39
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.8266 - loss: 0.4794 - val_accuracy: 0.7957 - val_loss: 0.5396
Q: 2002-276 T: 1726 ☒ 1656
Q: 49-5091 T: -5042 ☒ -5051
Q: 477-9534 T: -9057 ☒ -9066
Q: 406-9514 T: -9108 ☒ -9033
Q: 9-2752 T: -2743 ☒ -2733
Q: 487-0 T: 487 ☑ 487
Q: 314-759 T: -445 ☒ -465
Q: 2793-7076 T: -4283 ☒ -4354
Q: 725-18 T: 707 ☑ 707
Q: 5001-276 T: 4725 ☒ 4534

--------------------------------------------------
Iteration 40
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8331 - loss: 0.4634 - val_accuracy: 0.7962 - val_loss: 0.5324
Q: 5145-112 T: 5033 ☒ 4023
Q: 5512-739 T: 4773 ☒ 4733
Q: 7669-5 T: 7664 ☑ 7664
Q: 241-50 T: 191 ☒ 101
Q: 9717-5415 T: 4302 ☒ 4653
Q: 792-406 T: 386 ☒ 366
Q: 288-4734 T: -4446 ☒ -4345
Q: 85-139 T: -54 ☑ -54
Q: 1171-985 T: 186 ☒ 975
Q: 9-117 T: -108 ☑ -108

--------------------------------------------------
Iteration 41
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8408 - loss: 0.4440 - val_accuracy: 0.8040 - val_loss: 0.5157
Q: 5014-369 T: 4645 ☒ 4545
Q: 2440-896 T: 1544 ☒ 1454
Q: 382-835 T: -453 ☑ -453
Q: 444-55 T: 389 ☑ 389
Q: 9-72 T: -63 ☑ -63
Q: 99-4942 T: -4843 ☒ -4893
Q: 35-267 T: -232 ☑ -232
Q: 6-3533 T: -3527 ☑ -3527
Q: 9752-555 T: 9197 ☒ 9372
Q: 44-11 T: 33 ☑ 33

--------------------------------------------------
Iteration 42
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 11ms/step - accuracy: 0.8472 - loss: 0.4287 - val_accuracy: 0.8104 - val_loss: 0.4997
Q: 24-915 T: -891 ☑ -891
Q: 517-7 T: 510 ☒ 500
Q: 0-408 T: -408 ☑ -408
Q: 738-93 T: 645 ☑ 645
Q: 8016-5225 T: 2791 ☒ 3819
Q: 7-5672 T: -5665 ☑ -5665
Q: 611-0 T: 611 ☒ 610
Q: 5-3476 T: -3471 ☑ -3471
Q: 10-94 T: -84 ☒ -85
Q: 1334-2772 T: -1438 ☒ -158

--------------------------------------------------
Iteration 43
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.8570 - loss: 0.4070 - val_accuracy: 0.8144 - val_loss: 0.4861
Q: 978-655 T: 323 ☑ 323
Q: 358-71 T: 287 ☑ 287
Q: 4033-2 T: 4031 ☑ 4031
Q: 5659-0 T: 5659 ☑ 5659
Q: 5276-4 T: 5272 ☑ 5272
Q: 161-89 T: 72 ☑ 72
Q: 7283-9322 T: -2039 ☒ -1499
Q: 3343-225 T: 3118 ☒ 3202
Q: 152-523 T: -371 ☒ -381
Q: 195-8 T: 187 ☑ 187

--------------------------------------------------
Iteration 44
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8595 - loss: 0.4002 - val_accuracy: 0.8242 - val_loss: 0.4690
Q: 3208-0 T: 3208 ☑ 3208
Q: 7939-38 T: 7901 ☒ 7910
Q: 8878-5 T: 8873 ☒ 8853
Q: 633-46 T: 587 ☑ 587
Q: 3-7368 T: -7365 ☑ -7365
Q: 88-40 T: 48 ☑ 48
Q: 8-349 T: -341 ☑ -341
Q: 7-5132 T: -5125 ☒ -5124
Q: 322-4182 T: -3860 ☒ -3880
Q: 1-1701 T: -1700 ☑ -1700

--------------------------------------------------
Iteration 45
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">4s</span> 14ms/step - accuracy: 0.8682 - loss: 0.3775 - val_accuracy: 0.8266 - val_loss: 0.4604
Q: 706-8685 T: -7979 ☒ -7090
Q: 3698-41 T: 3657 ☑ 3657
Q: 20-3270 T: -3250 ☑ -3250
Q: 8-974 T: -966 ☑ -966
Q: 0-5260 T: -5260 ☒ -5261
Q: 1207-7 T: 1200 ☒ 1190
Q: 88-63 T: 25 ☒ 24
Q: 96-810 T: -714 ☒ -715
Q: 63-66 T: -3 ☑ -3
Q: 5962-3500 T: 2462 ☒ 2491

--------------------------------------------------
Iteration 46
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8718 - loss: 0.3686 - val_accuracy: 0.8282 - val_loss: 0.4580
Q: 7-295 T: -288 ☑ -288
Q: 4614-95 T: 4519 ☒ 4529
Q: 32-5554 T: -5522 ☒ -5523
Q: 9-1046 T: -1037 ☑ -1037
Q: 77-5213 T: -5136 ☒ -5146
Q: 111-95 T: 16 ☒ 1
Q: 124-6 T: 118 ☑ 118
Q: 951-66 T: 885 ☑ 885
Q: 0-6626 T: -6626 ☑ -6626
Q: 760-984 T: -224 ☒ -234

--------------------------------------------------
Iteration 47
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 7ms/step - accuracy: 0.8772 - loss: 0.3540 - val_accuracy: 0.8349 - val_loss: 0.4421
Q: 1238-931 T: 307 ☒ 462
Q: 5833-57 T: 5776 ☒ 5766
Q: 6219-471 T: 5748 ☒ 5821
Q: 904-9 T: 895 ☒ 894
Q: 79-693 T: -614 ☑ -614
Q: 5690-4190 T: 1500 ☒ 1490
Q: 1851-35 T: 1816 ☒ 1856
Q: 8376-5971 T: 2405 ☒ 3654
Q: 35-907 T: -872 ☒ -862
Q: 450-60 T: 390 ☑ 390

--------------------------------------------------
Iteration 48
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 9ms/step - accuracy: 0.8795 - loss: 0.3457 - val_accuracy: 0.8336 - val_loss: 0.4450
Q: 4863-2 T: 4861 ☑ 4861
Q: 1137-8 T: 1129 ☑ 1129
Q: 2-3272 T: -3270 ☑ -3270
Q: 8830-737 T: 8093 ☒ 8023
Q: 285-56 T: 229 ☑ 229
Q: 2681-4496 T: -1815 ☒ -1826
Q: 5898-9 T: 5889 ☑ 5889
Q: 7743-19 T: 7724 ☑ 7724
Q: 0-8444 T: -8444 ☒ -8445
Q: 7-599 T: -592 ☑ -592

--------------------------------------------------
Iteration 49
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8876 - loss: 0.3308 - val_accuracy: 0.8409 - val_loss: 0.4264
Q: 5-313 T: -308 ☑ -308
Q: 254-55 T: 199 ☒ 190
Q: 221-5 T: 216 ☑ 216
Q: 85-139 T: -54 ☑ -54
Q: 501-9 T: 492 ☑ 492
Q: 2-23 T: -21 ☑ -21
Q: 4247-81 T: 4166 ☒ 4176
Q: 3379-8473 T: -5094 ☒ -5044
Q: 3-8272 T: -8269 ☒ -8270
Q: 642-50 T: 592 ☑ 592

--------------------------------------------------
Iteration 50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8892 - loss: 0.3185 - val_accuracy: 0.8473 - val_loss: 0.4105
Q: 290-953 T: -663 ☑ -663
Q: 725-575 T: 150 ☒ 189
Q: 4779-8 T: 4771 ☒ 4760
Q: 8703-42 T: 8661 ☒ 8671
Q: 1078-8 T: 1070 ☒ 1060
Q: 3519-5 T: 3514 ☑ 3514
Q: 20-8928 T: -8908 ☑ -8908
Q: 0-32 T: -32 ☑ -32
Q: 523-10 T: 513 ☑ 513
Q: 989-41 T: 948 ☑ 948
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.2).</p>
<p>a) Do you think this model performs well?  Why or why not?<br/>
b) What are its limitations?<br/>
c) What would you do to improve it?<br/>
d) Can you apply an attention mechanism to this model? Why or why not?</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="1.2)-my-answer:">1.2) my answer:<a class="anchor-link" href="#1.2)-my-answer:">¶</a></h2><p>a) The model demonstrates moderate but not exceptional performance in handling arithmetic subtraction tasks. With a validation accuracy of around 85%, it successfully handles basic subtractions and some complex cases, but struggles with situations requiring precise calculations, especially those involving carrying operations or close number differences. While it can reliably handle simple cases and negative numbers, its accuracy drops when dealing with more nuanced calculations, particularly those involving large numbers with small differences or problems requiring multiple carrying operations. This level of performance suggests that while the model has learned the basic patterns of subtraction, it hasn't fully mastered the more intricate aspects of arithmetic operations that would be necessary for real-world applications.</p>
<p>b)</p>
<p>Fixed Input Length: The model is constrained to handle only numbers up to a certain digit length (4 digits in this case)
Single Operation: It's specialized for subtraction only and can't handle other arithmetic operations
No Explicit Carrying Mechanism: The LSTM has to learn carrying/borrowing implicitly
Limited Generalization: The validation accuracy suggests it may not generalize perfectly to unseen number combinations</p>
<p>c)</p>
<p>The architecture could be strengthened by adding residual connections and attention mechanisms, helping the model better handle complex calculations. The training process could be improved through curriculum learning, starting with simple problems and gradually increasing difficulty, while also expanding the training data to include more challenging edge cases like numbers requiring multiple carries or those with similar digits.</p>
<p>d)</p>
<p>Yes, an attention mechanism can be applied to this model, and it would be particularly beneficial for arithmetic operations.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.3).</p>
<p>Add attention to the model. Evaluate the performance against the <code>seq2seq</code> you trained above. Which one is performing better?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">attention_model</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">n_chars</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>

    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">n_chars</span><span class="p">))</span>

    <span class="c1"># Encoder</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
    <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="n">encoder</span>

    <span class="c1"># Decoder</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">RepeatVector</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)(</span><span class="n">state_h</span><span class="p">)</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">decoder</span><span class="p">)</span>

    <span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">()([</span><span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">])</span>

    <span class="n">decoder_combined</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Concatenate</span><span class="p">()([</span><span class="n">decoder</span><span class="p">,</span> <span class="n">attention</span><span class="p">])</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_chars</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))(</span><span class="n">decoder_combined</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span>
                 <span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span>
                 <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">attention_model</span><span class="p">(</span>
    <span class="n">maxlen</span><span class="o">=</span><span class="n">maxlen</span><span class="p">,</span>
    <span class="n">n_chars</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">),</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># Training loop with updated prediction handling</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Iteration'</span><span class="p">,</span> <span class="n">iteration</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
             <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span>
             <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
             <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>

    <span class="c1"># Validate on 10 random samples</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span>
        <span class="n">rowx</span><span class="p">,</span> <span class="n">rowy</span> <span class="o">=</span> <span class="n">x_val</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ind</span><span class="p">])],</span> <span class="n">y_val</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ind</span><span class="p">])]</span>

        <span class="c1"># Updated prediction handling - using argmax on the raw predictions</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">rowx</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">pred_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">rowx</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">rowy</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">guess</span> <span class="o">=</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ctable</span><span class="o">.</span><span class="n">indices_char</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pred_classes</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">'Q:'</span><span class="p">,</span> <span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'T:'</span><span class="p">,</span> <span class="n">correct</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">correct</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="n">guess</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'☑'</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'☒'</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">guess</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "functional_1"</span>
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)              </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">        Param # </span>┃<span style="font-weight: bold"> Connected to           </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer_3             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">9</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>)          │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ -                      │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)              │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ lstm_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">LSTM</span>)             │ [(<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">9</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>),       │         <span style="color: #00af00; text-decoration-color: #00af00">72,704</span> │ input_layer_3[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]    │
│                           │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>), (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>,    │                │                        │
│                           │ <span style="color: #00af00; text-decoration-color: #00af00">128</span>)]                  │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ repeat_vector_2           │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ lstm_4[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">1</span>]           │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">RepeatVector</span>)            │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ lstm_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">LSTM</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         │        <span style="color: #00af00; text-decoration-color: #00af00">131,584</span> │ repeat_vector_2[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]  │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ attention_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Attention</span>)   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ lstm_5[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>],          │
│                           │                        │                │ lstm_4[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]           │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ concatenate (<span style="color: #0087ff; text-decoration-color: #0087ff">Concatenate</span>) │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)         │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ lstm_5[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>],          │
│                           │                        │                │ attention_1[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ time_distributed_1        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>)          │          <span style="color: #00af00; text-decoration-color: #00af00">3,341</span> │ concatenate[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]      │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">TimeDistributed</span>)         │                        │                │                        │
└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">207,629</span> (811.05 KB)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">207,629</span> (811.05 KB)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
--------------------------------------------------
Iteration 1
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">6s</span> 11ms/step - accuracy: 0.3007 - loss: 2.0927 - val_accuracy: 0.4025 - val_loss: 1.7654
Q: 568-26 T: 542 ☒ 566
Q: 6978-50 T: 6928 ☒ 666
Q: 5160-322 T: 4838 ☒ 250
Q: 2-3873 T: -3871 ☒ -2222
Q: 4523-9 T: 4514 ☒ 540
Q: 186-4149 T: -3963 ☒ -100
Q: 2-5897 T: -5895 ☒ -2222
Q: 3760-530 T: 3230 ☒ 266
Q: 557-33 T: 524 ☒ 550
Q: 4-8061 T: -8057 ☒ -1620

--------------------------------------------------
Iteration 2
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 11ms/step - accuracy: 0.4218 - loss: 1.6356 - val_accuracy: 0.4406 - val_loss: 1.5686
Q: 93-46 T: 47 ☒ 33
Q: 6724-70 T: 6654 ☒ 6666
Q: 8878-5 T: 8873 ☒ 8888
Q: 83-2584 T: -2501 ☒ -2208
Q: 48-7204 T: -7156 ☒ -4708
Q: 2411-97 T: 2314 ☒ 1112
Q: 794-3326 T: -2532 ☒ -309
Q: 8692-67 T: 8625 ☒ 6888
Q: 805-8504 T: -7699 ☒ -500
Q: 43-44 T: -1 ☒ 33

--------------------------------------------------
Iteration 3
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.4463 - loss: 1.5381 - val_accuracy: 0.4561 - val_loss: 1.4884
Q: 153-6179 T: -6026 ☒ -6000
Q: 94-55 T: 39 ☒ 44
Q: 28-1997 T: -1969 ☒ -8802
Q: 64-103 T: -39 ☒ -30
Q: 65-438 T: -373 ☒ -358
Q: 63-632 T: -569 ☒ -208
Q: 212-74 T: 138 ☒ 21
Q: 46-7461 T: -7415 ☒ -6644
Q: 5987-96 T: 5891 ☒ 8885
Q: 1269-3839 T: -2570 ☒ -2211

--------------------------------------------------
Iteration 4
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 11ms/step - accuracy: 0.4588 - loss: 1.4701 - val_accuracy: 0.4721 - val_loss: 1.4239
Q: 20-408 T: -388 ☒ -407
Q: 493-281 T: 212 ☒ 349
Q: 115-471 T: -356 ☒ -11
Q: 22-2937 T: -2915 ☒ -2222
Q: 8929-20 T: 8909 ☒ 8889
Q: 163-4740 T: -4577 ☒ -4666
Q: 526-925 T: -399 ☒ -555
Q: 339-68 T: 271 ☒ 33
Q: 4371-267 T: 4104 ☒ 3477
Q: 58-7341 T: -7283 ☒ -8555

--------------------------------------------------
Iteration 5
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.4791 - loss: 1.4040 - val_accuracy: 0.4878 - val_loss: 1.3676
Q: 966-24 T: 942 ☒ 666
Q: 68-932 T: -864 ☒ -866
Q: 55-4859 T: -4804 ☒ -5485
Q: 4-6998 T: -6994 ☒ -9993
Q: 296-9202 T: -8906 ☒ -9096
Q: 950-7 T: 943 ☒ 999
Q: 246-3 T: 243 ☒ 222
Q: 13-362 T: -349 ☒ -336
Q: 4642-9207 T: -4565 ☒ -4444
Q: 216-2766 T: -2550 ☒ -2566

--------------------------------------------------
Iteration 6
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.5012 - loss: 1.3418 - val_accuracy: 0.5145 - val_loss: 1.3166
Q: 84-980 T: -896 ☒ -800
Q: 6-6334 T: -6328 ☒ -6320
Q: 7-837 T: -830 ☒ -870
Q: 3992-2421 T: 1571 ☒ 299
Q: 67-4982 T: -4915 ☒ -4766
Q: 46-3746 T: -3700 ☒ -3340
Q: 2-487 T: -485 ☒ -442
Q: 97-7214 T: -7117 ☒ -7000
Q: 33-195 T: -162 ☒ -103
Q: 97-2745 T: -2648 ☒ -2299

--------------------------------------------------
Iteration 7
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.5224 - loss: 1.2892 - val_accuracy: 0.5337 - val_loss: 1.2579
Q: 312-3524 T: -3212 ☒ -3099
Q: 42-92 T: -50 ☒ -44
Q: 444-55 T: 389 ☒ 444
Q: 234-8 T: 226 ☒ 222
Q: 2940-1034 T: 1906 ☒ 2999
Q: 9189-4718 T: 4471 ☒ 1999
Q: 67-244 T: -177 ☒ -266
Q: 161-89 T: 72 ☒ 11
Q: 5-349 T: -344 ☒ -330
Q: 4416-338 T: 4078 ☒ 4009

--------------------------------------------------
Iteration 8
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 11ms/step - accuracy: 0.5445 - loss: 1.2325 - val_accuracy: 0.5506 - val_loss: 1.2200
Q: 122-58 T: 64 ☒ 14
Q: 0-6533 T: -6533 ☒ -6330
Q: 1-3535 T: -3534 ☒ -3531
Q: 388-9092 T: -8704 ☒ -8833
Q: 5-7792 T: -7787 ☒ -7740
Q: 8878-5 T: 8873 ☒ 8888
Q: 25-242 T: -217 ☒ -110
Q: 2781-273 T: 2508 ☒ 2744
Q: 524-69 T: 455 ☒ 478
Q: 241-50 T: 191 ☒ 144

--------------------------------------------------
Iteration 9
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.5588 - loss: 1.1976 - val_accuracy: 0.5627 - val_loss: 1.1680
Q: 130-50 T: 80 ☒ 19
Q: 167-65 T: 102 ☒ 111
Q: 3884-89 T: 3795 ☒ 3783
Q: 5575-726 T: 4849 ☒ 4709
Q: 9-4410 T: -4401 ☒ -4429
Q: 4670-1 T: 4669 ☒ 4666
Q: 5512-739 T: 4773 ☒ 5508
Q: 3-9722 T: -9719 ☒ -9935
Q: 5-766 T: -761 ☑ -761
Q: 924-59 T: 865 ☒ 999

--------------------------------------------------
Iteration 10
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.5729 - loss: 1.1505 - val_accuracy: 0.5783 - val_loss: 1.1409
Q: 7794-524 T: 7270 ☒ 7449
Q: 706-640 T: 66 ☒ 14
Q: 8601-8 T: 8593 ☒ 8600
Q: 22-2937 T: -2915 ☒ -2988
Q: 7051-69 T: 6982 ☒ 7099
Q: 167-8452 T: -8285 ☒ -8268
Q: 412-51 T: 361 ☒ 366
Q: 7-6598 T: -6591 ☒ -6588
Q: 420-1212 T: -792 ☒ -100
Q: 5950-61 T: 5889 ☒ 5777

--------------------------------------------------
Iteration 11
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.5864 - loss: 1.1183 - val_accuracy: 0.5944 - val_loss: 1.0974
Q: 3613-9350 T: -5737 ☒ -5333
Q: 6613-3 T: 6610 ☒ 6613
Q: 4476-84 T: 4392 ☒ 4413
Q: 8880-445 T: 8435 ☒ 8388
Q: 3045-39 T: 3006 ☑ 3006
Q: 5892-1 T: 5891 ☒ 5882
Q: 59-65 T: -6 ☒ 11
Q: 11-930 T: -919 ☒ -918
Q: 6160-41 T: 6119 ☒ 6161
Q: 5-744 T: -739 ☒ -745

--------------------------------------------------
Iteration 12
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.5978 - loss: 1.0890 - val_accuracy: 0.5943 - val_loss: 1.0857
Q: 76-803 T: -727 ☒ -722
Q: 9-9353 T: -9344 ☒ -9354
Q: 1-125 T: -124 ☒ -122
Q: 2-5609 T: -5607 ☒ -5599
Q: 9155-2 T: 9153 ☒ 9184
Q: 894-6241 T: -5347 ☒ -5444
Q: 7455-74 T: 7381 ☒ 7366
Q: 82-10 T: 72 ☒ 70
Q: 237-9293 T: -9056 ☒ -9095
Q: 4-5688 T: -5684 ☒ -5666

--------------------------------------------------
Iteration 13
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6058 - loss: 1.0620 - val_accuracy: 0.6059 - val_loss: 1.0533
Q: 714-566 T: 148 ☒ 118
Q: 5705-6 T: 5699 ☒ 5772
Q: 686-54 T: 632 ☒ 615
Q: 3156-2596 T: 560 ☒ 108
Q: 199-7 T: 192 ☒ 184
Q: 1298-6 T: 1292 ☒ 1188
Q: 6-976 T: -970 ☒ -969
Q: 820-158 T: 662 ☒ 672
Q: 58-464 T: -406 ☒ -408
Q: 659-7574 T: -6915 ☒ -6188

--------------------------------------------------
Iteration 14
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6177 - loss: 1.0349 - val_accuracy: 0.6042 - val_loss: 1.0465
Q: 7-9290 T: -9283 ☑ -9283
Q: 1586-77 T: 1509 ☒ 1537
Q: 4134-52 T: 4082 ☒ 4126
Q: 3433-9138 T: -5705 ☒ -5600
Q: 221-5 T: 216 ☒ 227
Q: 3156-2596 T: 560 ☒ 100
Q: 304-4 T: 300 ☒ 309
Q: 6647-99 T: 6548 ☒ 6463
Q: 41-812 T: -771 ☒ -766
Q: 33-329 T: -296 ☑ -296

--------------------------------------------------
Iteration 15
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 11ms/step - accuracy: 0.6240 - loss: 1.0123 - val_accuracy: 0.6219 - val_loss: 1.0132
Q: 2-443 T: -441 ☒ -442
Q: 6702-4 T: 6698 ☒ 6600
Q: 111-95 T: 16 ☒ 15
Q: 7592-2013 T: 5579 ☒ 5699
Q: 5-850 T: -845 ☒ -840
Q: 28-220 T: -192 ☒ -199
Q: 44-3049 T: -3005 ☒ -3990
Q: 2-645 T: -643 ☑ -643
Q: 1366-70 T: 1296 ☒ 1335
Q: 439-858 T: -419 ☒ -480

--------------------------------------------------
Iteration 16
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6346 - loss: 0.9879 - val_accuracy: 0.6251 - val_loss: 0.9979
Q: 500-7289 T: -6789 ☒ -6888
Q: 1-660 T: -659 ☒ -660
Q: 4467-455 T: 4012 ☒ 4903
Q: 36-136 T: -100 ☒ -10
Q: 5258-525 T: 4733 ☒ 4965
Q: 470-541 T: -71 ☒ -15
Q: 20-408 T: -388 ☒ -399
Q: 9233-1492 T: 7741 ☒ 8880
Q: 0-5007 T: -5007 ☒ -5009
Q: 1463-8 T: 1455 ☒ 1458

--------------------------------------------------
Iteration 17
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6410 - loss: 0.9700 - val_accuracy: 0.6302 - val_loss: 0.9843
Q: 2404-6191 T: -3787 ☒ -2522
Q: 55-948 T: -893 ☒ -895
Q: 97-954 T: -857 ☒ -856
Q: 8512-63 T: 8449 ☒ 8416
Q: 3-12 T: -9 ☒ -1
Q: 482-5822 T: -5340 ☒ -5977
Q: 4241-4047 T: 194 ☒ -76
Q: 72-597 T: -525 ☒ -511
Q: 6383-4398 T: 1985 ☒ 2863
Q: 162-417 T: -255 ☒ -266

--------------------------------------------------
Iteration 18
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6488 - loss: 0.9471 - val_accuracy: 0.6394 - val_loss: 0.9615
Q: 874-923 T: -49 ☒ -1
Q: 53-9831 T: -9778 ☒ -9884
Q: 8171-3852 T: 4319 ☒ 4699
Q: 3749-463 T: 3286 ☒ 3112
Q: 7-3226 T: -3219 ☒ -3222
Q: 1262-9752 T: -8490 ☒ -7585
Q: 3-253 T: -250 ☒ -251
Q: 44-9758 T: -9714 ☒ -9624
Q: 230-70 T: 160 ☒ 252
Q: 65-946 T: -881 ☒ -880

--------------------------------------------------
Iteration 19
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 9ms/step - accuracy: 0.6554 - loss: 0.9307 - val_accuracy: 0.6441 - val_loss: 0.9502
Q: 3760-530 T: 3230 ☒ 3169
Q: 3059-204 T: 2855 ☒ 2966
Q: 41-805 T: -764 ☒ -752
Q: 9891-6253 T: 3638 ☒ 3099
Q: 221-9185 T: -8964 ☒ -9064
Q: 6166-3690 T: 2476 ☒ 2889
Q: 26-91 T: -65 ☑ -65
Q: 7772-344 T: 7428 ☒ 7319
Q: 1-1069 T: -1068 ☒ -1055
Q: 2-8436 T: -8434 ☒ -8444

--------------------------------------------------
Iteration 20
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 7ms/step - accuracy: 0.6600 - loss: 0.9158 - val_accuracy: 0.6485 - val_loss: 0.9325
Q: 21-527 T: -506 ☒ -505
Q: 124-6 T: 118 ☒ 124
Q: 6761-4 T: 6757 ☒ 6651
Q: 4523-9 T: 4514 ☒ 4496
Q: 2825-4262 T: -1437 ☒ -144
Q: 0-8984 T: -8984 ☒ -8897
Q: 374-8645 T: -8271 ☒ -8292
Q: 575-2 T: 573 ☒ 575
Q: 7331-91 T: 7240 ☒ 7245
Q: 901-9325 T: -8424 ☒ -8525

--------------------------------------------------
Iteration 21
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6688 - loss: 0.8924 - val_accuracy: 0.6539 - val_loss: 0.9182
Q: 672-9412 T: -8740 ☒ -8766
Q: 552-8841 T: -8289 ☒ -8251
Q: 45-971 T: -926 ☒ -935
Q: 724-2724 T: -2000 ☒ -2902
Q: 340-229 T: 111 ☒ 104
Q: 2295-155 T: 2140 ☒ 2148
Q: 4389-5 T: 4384 ☑ 4384
Q: 9901-622 T: 9279 ☒ 9080
Q: 14-28 T: -14 ☑ -14
Q: 79-164 T: -85 ☒ -88

--------------------------------------------------
Iteration 22
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6732 - loss: 0.8801 - val_accuracy: 0.6560 - val_loss: 0.9148
Q: 7709-4 T: 7705 ☒ 7704
Q: 173-56 T: 117 ☒ 111
Q: 7520-629 T: 6891 ☒ 6793
Q: 6-5695 T: -5689 ☒ -5681
Q: 85-6606 T: -6521 ☒ -6500
Q: 59-2 T: 57 ☑ 57
Q: 3387-5 T: 3382 ☒ 3389
Q: 50-4531 T: -4481 ☒ -4409
Q: 558-933 T: -375 ☒ -345
Q: 8299-8 T: 8291 ☒ 8289

--------------------------------------------------
Iteration 23
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 9ms/step - accuracy: 0.6805 - loss: 0.8608 - val_accuracy: 0.6632 - val_loss: 0.8903
Q: 8-3032 T: -3024 ☒ -3032
Q: 578-6974 T: -6396 ☒ -6222
Q: 753-3 T: 750 ☒ 752
Q: 65-438 T: -373 ☒ -379
Q: 8565-1 T: 8564 ☒ 8556
Q: 7379-5862 T: 1517 ☒ 2199
Q: 896-0 T: 896 ☒ 886
Q: 9-2752 T: -2743 ☒ -2729
Q: 9135-35 T: 9100 ☒ 9176
Q: 2-3222 T: -3220 ☒ -3229

--------------------------------------------------
Iteration 24
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6843 - loss: 0.8489 - val_accuracy: 0.6590 - val_loss: 0.8947
Q: 953-7 T: 946 ☑ 946
Q: 1307-855 T: 452 ☒ 465
Q: 692-69 T: 623 ☒ 613
Q: 7-6443 T: -6436 ☒ -6437
Q: 3-83 T: -80 ☒ -70
Q: 8163-4 T: 8159 ☒ 8153
Q: 57-99 T: -42 ☒ -43
Q: 53-57 T: -4 ☒ -1
Q: 9-8239 T: -8230 ☒ -8219
Q: 30-4326 T: -4296 ☒ -4203

--------------------------------------------------
Iteration 25
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6892 - loss: 0.8364 - val_accuracy: 0.6703 - val_loss: 0.8752
Q: 8-7890 T: -7882 ☒ -7889
Q: 4-709 T: -705 ☒ -706
Q: 61-377 T: -316 ☒ -321
Q: 552-385 T: 167 ☒ 15
Q: 5172-3 T: 5169 ☒ 5150
Q: 43-7398 T: -7355 ☒ -7338
Q: 85-61 T: 24 ☒ 23
Q: 2-5897 T: -5895 ☒ -5887
Q: 6-894 T: -888 ☒ -889
Q: 24-910 T: -886 ☒ -887

--------------------------------------------------
Iteration 26
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 9ms/step - accuracy: 0.6964 - loss: 0.8182 - val_accuracy: 0.6744 - val_loss: 0.8605
Q: 7729-4288 T: 3441 ☒ 3499
Q: 15-3709 T: -3694 ☒ -3699
Q: 732-6586 T: -5854 ☒ -5999
Q: 9228-848 T: 8380 ☒ 8433
Q: 7881-26 T: 7855 ☒ 7838
Q: 156-9 T: 147 ☒ 158
Q: 2609-877 T: 1732 ☒ 1725
Q: 71-99 T: -28 ☒ -22
Q: 304-4 T: 300 ☒ 397
Q: 295-0 T: 295 ☑ 295

--------------------------------------------------
Iteration 27
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.6989 - loss: 0.8084 - val_accuracy: 0.6775 - val_loss: 0.8450
Q: 5091-6 T: 5085 ☒ 5092
Q: 9-603 T: -594 ☒ -590
Q: 549-89 T: 460 ☒ 458
Q: 688-567 T: 121 ☒ 200
Q: 5-3762 T: -3757 ☒ -3761
Q: 442-17 T: 425 ☒ 424
Q: 289-0 T: 289 ☒ 285
Q: 549-89 T: 460 ☒ 458
Q: 75-992 T: -917 ☒ -915
Q: 9379-0 T: 9379 ☒ 9364

--------------------------------------------------
Iteration 28
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7084 - loss: 0.7861 - val_accuracy: 0.6807 - val_loss: 0.8414
Q: 617-65 T: 552 ☒ 558
Q: 4-1878 T: -1874 ☑ -1874
Q: 870-13 T: 857 ☒ 858
Q: 3830-1660 T: 2170 ☒ 2226
Q: 583-758 T: -175 ☒ -189
Q: 470-541 T: -71 ☒ -84
Q: 46-773 T: -727 ☒ -738
Q: 4283-8 T: 4275 ☒ 4276
Q: 5527-96 T: 5431 ☒ 5464
Q: 4102-5024 T: -922 ☒ -1122

--------------------------------------------------
Iteration 29
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.7115 - loss: 0.7775 - val_accuracy: 0.6723 - val_loss: 0.8633
Q: 4-834 T: -830 ☒ -831
Q: 103-660 T: -557 ☒ -556
Q: 505-59 T: 446 ☒ 445
Q: 75-720 T: -645 ☒ -648
Q: 2-2922 T: -2920 ☒ -2919
Q: 4947-4 T: 4943 ☒ 4941
Q: 49-941 T: -892 ☒ -880
Q: 7-118 T: -111 ☑ -111
Q: 86-720 T: -634 ☒ -633
Q: 8830-737 T: 8093 ☒ 8069

--------------------------------------------------
Iteration 30
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7146 - loss: 0.7662 - val_accuracy: 0.6893 - val_loss: 0.8192
Q: 5741-8122 T: -2381 ☒ -2433
Q: 3169-42 T: 3127 ☒ 3103
Q: 0-12 T: -12 ☒ -11
Q: 82-567 T: -485 ☒ -496
Q: 504-7 T: 497 ☑ 497
Q: 66-4703 T: -4637 ☒ -4643
Q: 6852-5292 T: 1560 ☒ 1044
Q: 29-8196 T: -8167 ☒ -8162
Q: 122-9 T: 113 ☒ 115
Q: 354-503 T: -149 ☒ -167

--------------------------------------------------
Iteration 31
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7213 - loss: 0.7501 - val_accuracy: 0.6935 - val_loss: 0.8071
Q: 5-8430 T: -8425 ☒ -8428
Q: 1317-2 T: 1315 ☒ 1336
Q: 0-870 T: -870 ☑ -870
Q: 9-383 T: -374 ☒ -375
Q: 400-92 T: 308 ☒ 312
Q: 98-20 T: 78 ☒ 77
Q: 460-4 T: 456 ☒ 455
Q: 9271-1472 T: 7799 ☒ 8820
Q: 628-8 T: 620 ☒ 611
Q: 5430-552 T: 4878 ☒ 4880

--------------------------------------------------
Iteration 32
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">4s</span> 12ms/step - accuracy: 0.7255 - loss: 0.7400 - val_accuracy: 0.6965 - val_loss: 0.7937
Q: 1780-5 T: 1775 ☒ 1770
Q: 258-27 T: 231 ☒ 230
Q: 672-72 T: 600 ☒ 603
Q: 80-2009 T: -1929 ☒ -1904
Q: 85-965 T: -880 ☑ -880
Q: 386-895 T: -509 ☒ -596
Q: 3503-5 T: 3498 ☒ 3406
Q: 1207-7 T: 1200 ☒ 1109
Q: 9589-530 T: 9059 ☒ 9933
Q: 8164-7166 T: 998 ☒ 113

--------------------------------------------------
Iteration 33
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7303 - loss: 0.7250 - val_accuracy: 0.6958 - val_loss: 0.8007
Q: 377-500 T: -123 ☒ -216
Q: 9351-5 T: 9346 ☒ 9344
Q: 2-883 T: -881 ☒ -880
Q: 760-984 T: -224 ☒ -206
Q: 3863-31 T: 3832 ☒ 3802
Q: 3-9722 T: -9719 ☒ -9720
Q: 388-9092 T: -8704 ☒ -8909
Q: 713-153 T: 560 ☒ 569
Q: 6611-9590 T: -2979 ☒ -3108
Q: 7283-9322 T: -2039 ☒ -2199

--------------------------------------------------
Iteration 34
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7349 - loss: 0.7150 - val_accuracy: 0.7006 - val_loss: 0.7814
Q: 4-6185 T: -6181 ☒ -6184
Q: 192-5 T: 187 ☒ 186
Q: 4682-60 T: 4622 ☒ 4613
Q: 36-11 T: 25 ☒ 35
Q: 82-9216 T: -9134 ☒ -9157
Q: 27-919 T: -892 ☒ -997
Q: 7049-11 T: 7038 ☒ 7021
Q: 4752-8029 T: -3277 ☒ -3367
Q: 1-1701 T: -1700 ☑ -1700
Q: 3-1572 T: -1569 ☒ -1571

--------------------------------------------------
Iteration 35
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">4s</span> 13ms/step - accuracy: 0.7381 - loss: 0.7047 - val_accuracy: 0.7032 - val_loss: 0.7775
Q: 924-59 T: 865 ☒ 877
Q: 28-1997 T: -1969 ☒ -1964
Q: 297-3 T: 294 ☒ 295
Q: 896-0 T: 896 ☒ 895
Q: 5633-554 T: 5079 ☒ 5980
Q: 2-6661 T: -6659 ☒ -6650
Q: 3872-857 T: 3015 ☒ 3066
Q: 5-3476 T: -3471 ☑ -3471
Q: 952-238 T: 714 ☒ 715
Q: 2603-66 T: 2537 ☒ 2566

--------------------------------------------------
Iteration 36
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7433 - loss: 0.6916 - val_accuracy: 0.7043 - val_loss: 0.7811
Q: 1354-215 T: 1139 ☒ 1223
Q: 315-87 T: 228 ☒ 225
Q: 6-120 T: -114 ☒ -105
Q: 402-69 T: 333 ☒ 344
Q: 9-9003 T: -8994 ☒ -8001
Q: 84-1582 T: -1498 ☒ -1572
Q: 400-341 T: 59 ☒ 66
Q: 10-3639 T: -3629 ☒ -3622
Q: 965-296 T: 669 ☒ 678
Q: 31-4841 T: -4810 ☒ -4818

--------------------------------------------------
Iteration 37
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7441 - loss: 0.6899 - val_accuracy: 0.7122 - val_loss: 0.7497
Q: 8878-5 T: 8873 ☑ 8873
Q: 30-705 T: -675 ☒ -672
Q: 2465-4 T: 2461 ☒ 2452
Q: 3415-10 T: 3405 ☒ 3404
Q: 0-817 T: -817 ☑ -817
Q: 5789-534 T: 5255 ☒ 5244
Q: 9320-3226 T: 6094 ☒ 5994
Q: 269-8 T: 261 ☒ 260
Q: 9373-2 T: 9371 ☑ 9371
Q: 17-102 T: -85 ☒ -91

--------------------------------------------------
Iteration 38
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7519 - loss: 0.6682 - val_accuracy: 0.7038 - val_loss: 0.7785
Q: 331-9328 T: -8997 ☒ -9011
Q: 99-762 T: -663 ☒ -669
Q: 150-8194 T: -8044 ☒ -8011
Q: 5748-583 T: 5165 ☒ 5074
Q: 738-697 T: 41 ☒ -2
Q: 183-8223 T: -8040 ☒ -8041
Q: 175-58 T: 117 ☒ 118
Q: 7481-895 T: 6586 ☒ 6666
Q: 1332-87 T: 1245 ☒ 1254
Q: 965-296 T: 669 ☒ 671

--------------------------------------------------
Iteration 39
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.7554 - loss: 0.6587 - val_accuracy: 0.7127 - val_loss: 0.7430
Q: 21-9109 T: -9088 ☒ -9098
Q: 1-125 T: -124 ☑ -124
Q: 38-8168 T: -8130 ☒ -8129
Q: 80-602 T: -522 ☑ -522
Q: 678-417 T: 261 ☒ 249
Q: 54-8602 T: -8548 ☒ -8564
Q: 268-7 T: 261 ☒ 260
Q: 33-40 T: -7 ☑ -7
Q: 5898-9 T: 5889 ☒ 5880
Q: 3953-20 T: 3933 ☒ 3934

--------------------------------------------------
Iteration 40
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7593 - loss: 0.6490 - val_accuracy: 0.7166 - val_loss: 0.7398
Q: 48-385 T: -337 ☒ -338
Q: 7426-82 T: 7344 ☒ 7364
Q: 561-6 T: 555 ☑ 555
Q: 812-98 T: 714 ☑ 714
Q: 1-7442 T: -7441 ☒ -7440
Q: 1871-8218 T: -6347 ☒ -6390
Q: 5510-1 T: 5509 ☒ 5516
Q: 574-8 T: 566 ☑ 566
Q: 611-0 T: 611 ☒ 612
Q: 85-178 T: -93 ☒ -90

--------------------------------------------------
Iteration 41
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7643 - loss: 0.6370 - val_accuracy: 0.7264 - val_loss: 0.7227
Q: 61-885 T: -824 ☒ -825
Q: 218-4341 T: -4123 ☒ -4144
Q: 1514-99 T: 1415 ☒ 1451
Q: 45-5303 T: -5258 ☒ -5268
Q: 367-4576 T: -4209 ☒ -4200
Q: 5-658 T: -653 ☑ -653
Q: 80-999 T: -919 ☒ -920
Q: 1725-42 T: 1683 ☒ 1682
Q: 12-3840 T: -3828 ☑ -3828
Q: 8862-65 T: 8797 ☒ 8708

--------------------------------------------------
Iteration 42
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.7680 - loss: 0.6273 - val_accuracy: 0.7208 - val_loss: 0.7277
Q: 917-18 T: 899 ☒ 909
Q: 951-5254 T: -4303 ☒ -4390
Q: 202-98 T: 104 ☒ 111
Q: 659-670 T: -11 ☒ -10
Q: 43-7398 T: -7355 ☒ -7346
Q: 8371-4 T: 8367 ☒ 8374
Q: 918-113 T: 805 ☒ 796
Q: 6-9903 T: -9897 ☒ -9896
Q: 42-92 T: -50 ☑ -50
Q: 629-4 T: 625 ☒ 624

--------------------------------------------------
Iteration 43
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7717 - loss: 0.6150 - val_accuracy: 0.7176 - val_loss: 0.7255
Q: 4341-3314 T: 1027 ☒ 100
Q: 5941-363 T: 5578 ☒ 5661
Q: 7976-293 T: 7683 ☒ 7573
Q: 12-5877 T: -5865 ☒ -5867
Q: 8388-981 T: 7407 ☒ 7400
Q: 8064-5 T: 8059 ☒ 8050
Q: 6060-2 T: 6058 ☒ 6056
Q: 7-619 T: -612 ☒ -613
Q: 145-4515 T: -4370 ☒ -4383
Q: 10-16 T: -6 ☑ -6

--------------------------------------------------
Iteration 44
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7748 - loss: 0.6035 - val_accuracy: 0.7300 - val_loss: 0.7026
Q: 4041-374 T: 3667 ☒ 3781
Q: 293-3072 T: -2779 ☒ -2825
Q: 696-8016 T: -7320 ☒ -7325
Q: 172-618 T: -446 ☒ -433
Q: 5-599 T: -594 ☒ -593
Q: 775-774 T: 1 ☒ 18
Q: 17-64 T: -47 ☑ -47
Q: 5-5503 T: -5498 ☑ -5498
Q: 6837-89 T: 6748 ☒ 6756
Q: 10-16 T: -6 ☒ -4

--------------------------------------------------
Iteration 45
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 12ms/step - accuracy: 0.7802 - loss: 0.5914 - val_accuracy: 0.7272 - val_loss: 0.7004
Q: 4344-0 T: 4344 ☒ 4343
Q: 9-485 T: -476 ☑ -476
Q: 24-2442 T: -2418 ☒ -2428
Q: 7-170 T: -163 ☑ -163
Q: 27-919 T: -892 ☒ -900
Q: 78-1389 T: -1311 ☒ -1300
Q: 8830-737 T: 8093 ☒ 8146
Q: 2-4387 T: -4385 ☑ -4385
Q: 25-856 T: -831 ☒ -832
Q: 8759-3643 T: 5116 ☒ 6020

--------------------------------------------------
Iteration 46
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7834 - loss: 0.5855 - val_accuracy: 0.7359 - val_loss: 0.6874
Q: 8082-7 T: 8075 ☒ 8074
Q: 9084-792 T: 8292 ☒ 8260
Q: 406-9514 T: -9108 ☒ -9211
Q: 1334-2772 T: -1438 ☒ -1531
Q: 6-9733 T: -9727 ☒ -9728
Q: 694-7 T: 687 ☒ 686
Q: 4-238 T: -234 ☒ -233
Q: 617-65 T: 552 ☒ 555
Q: 3349-3229 T: 120 ☒ 109
Q: 8-95 T: -87 ☑ -87

--------------------------------------------------
Iteration 47
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7887 - loss: 0.5710 - val_accuracy: 0.7358 - val_loss: 0.6808
Q: 918-113 T: 805 ☒ 706
Q: 552-8841 T: -8289 ☒ -8311
Q: 7377-4 T: 7373 ☒ 7374
Q: 788-342 T: 446 ☒ 443
Q: 922-17 T: 905 ☒ 807
Q: 37-109 T: -72 ☒ -63
Q: 31-743 T: -712 ☒ -711
Q: 6-699 T: -693 ☒ -692
Q: 4457-611 T: 3846 ☒ 3853
Q: 4670-1 T: 4669 ☒ 4667

--------------------------------------------------
Iteration 48
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.7927 - loss: 0.5584 - val_accuracy: 0.7400 - val_loss: 0.6753
Q: 524-213 T: 311 ☒ 323
Q: 60-224 T: -164 ☒ -163
Q: 9775-3 T: 9772 ☒ 9773
Q: 98-136 T: -38 ☒ -37
Q: 379-30 T: 349 ☒ 347
Q: 85-178 T: -93 ☒ -10
Q: 2104-8663 T: -6559 ☒ -6543
Q: 661-91 T: 570 ☒ 583
Q: 90-216 T: -126 ☒ -134
Q: 8759-3643 T: 5116 ☒ 4144

--------------------------------------------------
Iteration 49
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">3s</span> 10ms/step - accuracy: 0.7972 - loss: 0.5478 - val_accuracy: 0.7357 - val_loss: 0.6705
Q: 916-4931 T: -4015 ☒ -394
Q: 506-6024 T: -5518 ☒ -5544
Q: 0-5007 T: -5007 ☒ -5005
Q: 2609-877 T: 1732 ☒ 1722
Q: 522-1837 T: -1315 ☒ -2333
Q: 167-841 T: -674 ☒ -675
Q: 740-78 T: 662 ☒ 653
Q: 0-104 T: -104 ☑ -104
Q: 41-305 T: -264 ☒ -273
Q: 2299-147 T: 2152 ☒ 2242

--------------------------------------------------
Iteration 50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg">━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-bold">2s</span> 8ms/step - accuracy: 0.8006 - loss: 0.5382 - val_accuracy: 0.7447 - val_loss: 0.6629
Q: 0-832 T: -832 ☑ -832
Q: 7213-20 T: 7193 ☑ 7193
Q: 1388-3 T: 1385 ☒ 1384
Q: 7829-490 T: 7339 ☒ 7292
Q: 8169-105 T: 8064 ☒ 8099
Q: 4-7409 T: -7405 ☑ -7405
Q: 269-8 T: 261 ☒ 260
Q: 5175-96 T: 5079 ☒ 5086
Q: 3050-2 T: 3048 ☒ 3044
Q: 795-11 T: 784 ☒ 774
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.4)</p>
<p>Using any neural network architecture of your liking, build  a model with the aim to beat the best performing model in 1.1 or 1.3. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">40000</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s1">'0123456789-+ '</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>SOLUTION:</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="c1"># Configuration</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"training_size"</span><span class="p">:</span> <span class="mi">40000</span><span class="p">,</span>
    <span class="s2">"digits"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">"embedding_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"num_heads"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s2">"num_layers"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s2">"ffn_hidden_size"</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
    <span class="s2">"dropout"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"iterations"</span><span class="p">:</span> <span class="mi">250</span><span class="p">,</span>
    <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s1">'0123456789-+ '</span>

<span class="k">class</span> <span class="nc">CharacterTable</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Handles encoding/decoding of characters to/from one-hot vectors"""</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chars</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">char_indices</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">indices_char</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_chars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">C</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""One hot encode given string C."""</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">char_indices</span><span class="p">[</span><span class="n">c</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">calc_argmax</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">calc_argmax</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">indices_char</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ArithmeticDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="o">-</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">))</span> <span class="o">/</span> <span class="n">embedding_size</span><span class="p">))</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">'pe'</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>

<span class="k">class</span> <span class="nc">TransformerModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ffn_hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_length</span> <span class="o">=</span> <span class="n">output_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">config</span><span class="p">[</span><span class="s1">'digits'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># Input embedding and positional encoding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">max_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_length</span><span class="p">)</span>

        <span class="c1"># Transformer Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">ffn_hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">num_layers</span>
        <span class="p">)</span>

        <span class="c1"># Output layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>

        <span class="c1"># Embed and add positional encoding</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">)</span> <span class="c1">#scaling for stability</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Transformer Encoder</span>
        <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Project the output of each token to desired output length</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_arithmetic_data</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">"""Generate data for both addition and subtraction"""</span>
    <span class="n">questions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'Generating data...'</span><span class="p">)</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]:</span>
        <span class="c1"># Generate random numbers with max length of digits</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Randomly choose operation</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'+'</span><span class="p">,</span> <span class="s1">'-'</span><span class="p">])</span>

        <span class="c1"># Calculate result</span>
        <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s1">'+'</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span>

        <span class="c1"># Create question string</span>
        <span class="n">q</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">op</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s1">'</span>

        <span class="c1"># Skip if we've seen this before</span>
        <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="c1"># Pad the data</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">q</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">*</span> <span class="p">(</span><span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="n">ans</span> <span class="o">+=</span> <span class="s1">' '</span> <span class="o">*</span> <span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">ans</span><span class="p">))</span>

        <span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">expected</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]:</span>
            <span class="k">break</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Total arithmetic questions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">questions</span><span class="p">,</span> <span class="n">expected</span>

<span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="n">questions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">expected</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">ctable</span><span class="p">:</span> <span class="n">CharacterTable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Prepare data by converting to one-hot encoded tensors"""</span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">maxlen</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">questions</span><span class="p">):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">expected</span><span class="p">):</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Train for one epoch"""</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_samples</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">batch_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="p">:</span><span class="n">config</span><span class="p">[</span><span class="s1">'digits'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)),</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Calculate accuracy</span>
        <span class="n">predicted_chars</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="p">:</span><span class="n">config</span><span class="p">[</span><span class="s1">'digits'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">true_chars</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">batch_y</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">correct_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_chars</span> <span class="o">==</span> <span class="n">true_chars</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">total_correct</span> <span class="o">+=</span> <span class="n">correct_predictions</span>
        <span class="n">total_samples</span> <span class="o">+=</span> <span class="n">batch_x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">total_correct</span> <span class="o">/</span> <span class="n">total_samples</span> <span class="k">if</span> <span class="n">total_samples</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">accuracy</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Validate the model"""</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_samples</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">batch_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="p">:</span><span class="n">config</span><span class="p">[</span><span class="s1">'digits'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)),</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># Calculate accuracy</span>
            <span class="n">predicted_chars</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="p">:</span><span class="n">config</span><span class="p">[</span><span class="s1">'digits'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">true_chars</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">batch_y</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">correct_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_chars</span> <span class="o">==</span> <span class="n">true_chars</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_correct</span> <span class="o">+=</span> <span class="n">correct_predictions</span>
            <span class="n">total_samples</span> <span class="o">+=</span> <span class="n">batch_x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">total_correct</span> <span class="o">/</span> <span class="n">total_samples</span> <span class="k">if</span> <span class="n">total_samples</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">),</span> <span class="n">accuracy</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Set device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># Initialize character table</span>
    <span class="n">ctable</span> <span class="o">=</span> <span class="n">CharacterTable</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

    <span class="c1"># Generate and prepare data</span>
    <span class="n">questions</span><span class="p">,</span> <span class="n">expected</span> <span class="o">=</span> <span class="n">generate_arithmetic_data</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">questions</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">ctable</span><span class="p">)</span>

    <span class="c1"># Shuffle data</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="c1"># Split data</span>
    <span class="n">split_at</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">x_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>

    <span class="c1"># Create datasets and dataloaders</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ArithmeticDataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">ArithmeticDataset</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">])</span>

    <span class="c1"># Initialize model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">TransformerModel</span><span class="p">(</span>
        <span class="n">input_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">),</span>
        <span class="n">embedding_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"embedding_size"</span><span class="p">],</span>
        <span class="n">num_heads</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"num_heads"</span><span class="p">],</span>
        <span class="n">num_layers</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"num_layers"</span><span class="p">],</span>
        <span class="n">output_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">),</span>
        <span class="n">output_length</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ffn_hidden_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"ffn_hidden_size"</span><span class="p">],</span>
        <span class="n">dropout</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"dropout"</span><span class="p">]</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">])</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># Training loop</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Starting training..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">]):</span>
        <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">]</span><span class="si">}</span><span class="s1">:'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

        <span class="c1"># Validation samples</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Validation Examples:"</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span>
                    <span class="n">x_sample</span> <span class="o">=</span> <span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_val</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

                    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_sample</span><span class="p">)</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

                    <span class="n">q</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x_sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
                    <span class="n">correct</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
                    <span class="n">guess</span> <span class="o">=</span> <span class="n">ctable</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="n">config</span><span class="p">[</span><span class="s1">'digits'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>

                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Question: </span><span class="si">{</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s1"> | True: </span><span class="si">{</span><span class="n">correct</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s1"> | '</span>
                          <span class="sa">f</span><span class="s1">'Predicted: </span><span class="si">{</span><span class="n">guess</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s1"> | '</span>
                          <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="s2">"✓"</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">correct</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">guess</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s2">"✗"</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Using device: cuda
Generating data...
Total arithmetic questions: 40000
Starting training...
Epoch 1/250:
Train Loss: 2.4428, Train Accuracy: 0.0001, Val Loss: 2.4005, Val Accuracy: 0.0000

Validation Examples:
Question: 4576-3464 | True: 1112 | Predicted: -113 | ✗
Question: 3250-4777 | True: -1527 | Predicted: --13 | ✗
Question: 9670+3822 | True: 13492 | Predicted: 1111 | ✗
Question: 6353-6167 | True: 186 | Predicted: 1-13 | ✗
Question: 3854-5930 | True: -2076 | Predicted: -113 | ✗

Epoch 2/250:
Train Loss: 2.3925, Train Accuracy: 0.0001, Val Loss: 2.3864, Val Accuracy: 0.0003
Epoch 3/250:
Train Loss: 2.3869, Train Accuracy: 0.0001, Val Loss: 2.3832, Val Accuracy: 0.0003
Epoch 4/250:
Train Loss: 2.3839, Train Accuracy: 0.0001, Val Loss: 2.3805, Val Accuracy: 0.0003
Epoch 5/250:
Train Loss: 2.3812, Train Accuracy: 0.0001, Val Loss: 2.3787, Val Accuracy: 0.0003
Epoch 6/250:
Train Loss: 2.3789, Train Accuracy: 0.0001, Val Loss: 2.3755, Val Accuracy: 0.0000

Validation Examples:
Question: 9781+6054 | True: 15835 | Predicted: 1730 | ✗
Question: 9773+2037 | True: 11810 | Predicted: 1774 | ✗
Question: 4368+631 | True: 4999 | Predicted: 5344 | ✗
Question: 1588-3161 | True: -1573 | Predicted: -113 | ✗
Question: 9755-8441 | True: 1314 | Predicted: 3211 | ✗

Epoch 7/250:
Train Loss: 2.3760, Train Accuracy: 0.0002, Val Loss: 2.3719, Val Accuracy: 0.0005
Epoch 8/250:
Train Loss: 2.3729, Train Accuracy: 0.0003, Val Loss: 2.3698, Val Accuracy: 0.0005
Epoch 9/250:
Train Loss: 2.3694, Train Accuracy: 0.0002, Val Loss: 2.3655, Val Accuracy: 0.0005
Epoch 10/250:
Train Loss: 2.3646, Train Accuracy: 0.0003, Val Loss: 2.3602, Val Accuracy: 0.0003
Epoch 11/250:
Train Loss: 2.3594, Train Accuracy: 0.0004, Val Loss: 2.3546, Val Accuracy: 0.0010

Validation Examples:
Question: 5412-9155 | True: -3743 | Predicted: -433 | ✗
Question: 4368+631 | True: 4999 | Predicted: 5445 | ✗
Question: 2322-823 | True: 1499 | Predicted: -111 | ✗
Question: 731+6313 | True: 7044 | Predicted: 744 | ✗
Question: 9598+499 | True: 10097 | Predicted: 1003 | ✗

Epoch 12/250:
Train Loss: 2.3534, Train Accuracy: 0.0004, Val Loss: 2.3482, Val Accuracy: 0.0018
Epoch 13/250:
Train Loss: 2.3464, Train Accuracy: 0.0008, Val Loss: 2.3370, Val Accuracy: 0.0015
Epoch 14/250:
Train Loss: 2.3358, Train Accuracy: 0.0016, Val Loss: 2.3216, Val Accuracy: 0.0040
Epoch 15/250:
Train Loss: 2.3231, Train Accuracy: 0.0029, Val Loss: 2.3072, Val Accuracy: 0.0030
Epoch 16/250:
Train Loss: 2.3095, Train Accuracy: 0.0037, Val Loss: 2.2913, Val Accuracy: 0.0067

Validation Examples:
Question: 7662+9916 | True: 17578 | Predicted: 16581 | ✗
Question: 1065+6292 | True: 7357 | Predicted: 8053 | ✗
Question: 9926+9154 | True: 19080 | Predicted: 11310 | ✗
Question: 7654-8257 | True: -603 | Predicted: -111 | ✗
Question: 535-9502 | True: -8967 | Predicted: -35 | ✗

Epoch 17/250:
Train Loss: 2.2966, Train Accuracy: 0.0064, Val Loss: 2.2755, Val Accuracy: 0.0092
Epoch 18/250:
Train Loss: 2.2819, Train Accuracy: 0.0093, Val Loss: 2.2569, Val Accuracy: 0.0123
Epoch 19/250:
Train Loss: 2.2646, Train Accuracy: 0.0126, Val Loss: 2.2309, Val Accuracy: 0.0260
Epoch 20/250:
Train Loss: 2.2447, Train Accuracy: 0.0184, Val Loss: 2.2007, Val Accuracy: 0.0365
Epoch 21/250:
Train Loss: 2.2207, Train Accuracy: 0.0267, Val Loss: 2.1683, Val Accuracy: 0.0545

Validation Examples:
Question: 8276+7719 | True: 15995 | Predicted: 15655 | ✗
Question: 4591-8521 | True: -3930 | Predicted: -332 | ✗
Question: 1820+8376 | True: 10196 | Predicted: 1096 | ✗
Question: 3806+2871 | True: 6677 | Predicted: 5697 | ✗
Question: 1305-1007 | True: 298 | Predicted: -302 | ✗

Epoch 22/250:
Train Loss: 2.1939, Train Accuracy: 0.0375, Val Loss: 2.1422, Val Accuracy: 0.0725
Epoch 23/250:
Train Loss: 2.1728, Train Accuracy: 0.0482, Val Loss: 2.1246, Val Accuracy: 0.0833
Epoch 24/250:
Train Loss: 2.1570, Train Accuracy: 0.0589, Val Loss: 2.1162, Val Accuracy: 0.0998
Epoch 25/250:
Train Loss: 2.1464, Train Accuracy: 0.0661, Val Loss: 2.1074, Val Accuracy: 0.0998
Epoch 26/250:
Train Loss: 2.1383, Train Accuracy: 0.0734, Val Loss: 2.0995, Val Accuracy: 0.1062

Validation Examples:
Question: 795-590 | True: 205 | Predicted: -45 | ✗
Question: 7256-4636 | True: 2620 | Predicted: 2610 | ✗
Question: 5794+3258 | True: 9052 | Predicted: 8042 | ✗
Question: 8452-4275 | True: 4177 | Predicted: 4287 | ✗
Question: 2534+8695 | True: 11229 | Predicted: 11299 | ✗

Epoch 27/250:
Train Loss: 2.1295, Train Accuracy: 0.0786, Val Loss: 2.0945, Val Accuracy: 0.1100
Epoch 28/250:
Train Loss: 2.1238, Train Accuracy: 0.0841, Val Loss: 2.0889, Val Accuracy: 0.1175
Epoch 29/250:
Train Loss: 2.1165, Train Accuracy: 0.0930, Val Loss: 2.0810, Val Accuracy: 0.1275
Epoch 30/250:
Train Loss: 2.1109, Train Accuracy: 0.0984, Val Loss: 2.0761, Val Accuracy: 0.1353
Epoch 31/250:
Train Loss: 2.1057, Train Accuracy: 0.1034, Val Loss: 2.0713, Val Accuracy: 0.1403

Validation Examples:
Question: 3165+9934 | True: 13099 | Predicted: 13099 | ✓
Question: 9513+8096 | True: 17609 | Predicted: 17099 | ✗
Question: 5832+6287 | True: 12119 | Predicted: 12199 | ✗
Question: 8888+6989 | True: 15877 | Predicted: 16777 | ✗
Question: 3506+3678 | True: 7184 | Predicted: 7274 | ✗

Epoch 32/250:
Train Loss: 2.0985, Train Accuracy: 0.1147, Val Loss: 2.0620, Val Accuracy: 0.1600
Epoch 33/250:
Train Loss: 2.0920, Train Accuracy: 0.1244, Val Loss: 2.0538, Val Accuracy: 0.1787
Epoch 34/250:
Train Loss: 2.0856, Train Accuracy: 0.1351, Val Loss: 2.0473, Val Accuracy: 0.1945
Epoch 35/250:
Train Loss: 2.0792, Train Accuracy: 0.1446, Val Loss: 2.0380, Val Accuracy: 0.2230
Epoch 36/250:
Train Loss: 2.0724, Train Accuracy: 0.1571, Val Loss: 2.0300, Val Accuracy: 0.2320

Validation Examples:
Question: 5843+2504 | True: 8347 | Predicted: 8347 | ✓
Question: 831+7006 | True: 7837 | Predicted: 7517 | ✗
Question: 8786-8985 | True: -199 | Predicted: -111 | ✗
Question: 1315+1202 | True: 2517 | Predicted: 2517 | ✓
Question: 9136-6772 | True: 2364 | Predicted: 2464 | ✗

Epoch 37/250:
Train Loss: 2.0655, Train Accuracy: 0.1659, Val Loss: 2.0203, Val Accuracy: 0.2567
Epoch 38/250:
Train Loss: 2.0587, Train Accuracy: 0.1821, Val Loss: 2.0143, Val Accuracy: 0.2660
Epoch 39/250:
Train Loss: 2.0517, Train Accuracy: 0.1953, Val Loss: 2.0040, Val Accuracy: 0.2945
Epoch 40/250:
Train Loss: 2.0446, Train Accuracy: 0.2090, Val Loss: 1.9945, Val Accuracy: 0.3137
Epoch 41/250:
Train Loss: 2.0354, Train Accuracy: 0.2266, Val Loss: 1.9879, Val Accuracy: 0.3365

Validation Examples:
Question: 7423-5607 | True: 1816 | Predicted: 1816 | ✓
Question: 1972-1330 | True: 642 | Predicted: -642 | ✗
Question: 7019-468 | True: 6551 | Predicted: 6551 | ✓
Question: 6699+516 | True: 7215 | Predicted: 7215 | ✓
Question: 3189-1765 | True: 1424 | Predicted: 1424 | ✓

Epoch 42/250:
Train Loss: 2.0265, Train Accuracy: 0.2461, Val Loss: 1.9713, Val Accuracy: 0.3772
Epoch 43/250:
Train Loss: 2.0158, Train Accuracy: 0.2672, Val Loss: 1.9616, Val Accuracy: 0.4030
Epoch 44/250:
Train Loss: 2.0051, Train Accuracy: 0.2896, Val Loss: 1.9469, Val Accuracy: 0.4235
Epoch 45/250:
Train Loss: 1.9959, Train Accuracy: 0.3061, Val Loss: 1.9337, Val Accuracy: 0.4612
Epoch 46/250:
Train Loss: 1.9826, Train Accuracy: 0.3281, Val Loss: 1.9196, Val Accuracy: 0.4963

Validation Examples:
Question: 9743-6443 | True: 3300 | Predicted: 3300 | ✓
Question: 3882-8747 | True: -4865 | Predicted: -405 | ✗
Question: 2057-9018 | True: -6961 | Predicted: -713 | ✗
Question: 8953-1330 | True: 7623 | Predicted: 7623 | ✓
Question: 6324+3916 | True: 10240 | Predicted: 10480 | ✗

Epoch 47/250:
Train Loss: 1.9723, Train Accuracy: 0.3459, Val Loss: 1.9055, Val Accuracy: 0.5245
Epoch 48/250:
Train Loss: 1.9607, Train Accuracy: 0.3748, Val Loss: 1.8985, Val Accuracy: 0.5357
Epoch 49/250:
Train Loss: 1.9500, Train Accuracy: 0.3922, Val Loss: 1.8860, Val Accuracy: 0.5567
Epoch 50/250:
Train Loss: 1.9344, Train Accuracy: 0.4153, Val Loss: 1.8524, Val Accuracy: 0.6342
Epoch 51/250:
Train Loss: 1.9139, Train Accuracy: 0.4482, Val Loss: 1.8390, Val Accuracy: 0.6657

Validation Examples:
Question: 2441+1237 | True: 3678 | Predicted: 3678 | ✓
Question: 4647+7207 | True: 11854 | Predicted: 11854 | ✓
Question: 8380+4235 | True: 12615 | Predicted: 12615 | ✓
Question: 2205+9242 | True: 11447 | Predicted: 11447 | ✓
Question: 9235+1353 | True: 10588 | Predicted: 10588 | ✓

Epoch 52/250:
Train Loss: 1.9016, Train Accuracy: 0.4724, Val Loss: 1.8347, Val Accuracy: 0.6705
Epoch 53/250:
Train Loss: 1.8914, Train Accuracy: 0.4954, Val Loss: 1.8284, Val Accuracy: 0.6907
Epoch 54/250:
Train Loss: 1.8825, Train Accuracy: 0.5182, Val Loss: 1.8253, Val Accuracy: 0.6975
Epoch 55/250:
Train Loss: 1.8766, Train Accuracy: 0.5358, Val Loss: 1.8224, Val Accuracy: 0.7037
Epoch 56/250:
Train Loss: 1.8714, Train Accuracy: 0.5443, Val Loss: 1.8176, Val Accuracy: 0.7285

Validation Examples:
Question: 3177+5501 | True: 8678 | Predicted: 8678 | ✓
Question: 9361-8041 | True: 1320 | Predicted: 1320 | ✓
Question: 6632+3723 | True: 10355 | Predicted: 10355 | ✓
Question: 2123-8523 | True: -6400 | Predicted: -6400 | ✓
Question: 5015-7480 | True: -2465 | Predicted: -2465 | ✓

Epoch 57/250:
Train Loss: 1.8670, Train Accuracy: 0.5609, Val Loss: 1.8154, Val Accuracy: 0.7292
Epoch 58/250:
Train Loss: 1.8622, Train Accuracy: 0.5709, Val Loss: 1.8138, Val Accuracy: 0.7355
Epoch 59/250:
Train Loss: 1.8570, Train Accuracy: 0.5842, Val Loss: 1.8112, Val Accuracy: 0.7372
Epoch 60/250:
Train Loss: 1.8539, Train Accuracy: 0.5937, Val Loss: 1.8126, Val Accuracy: 0.7400
Epoch 61/250:
Train Loss: 1.8516, Train Accuracy: 0.6003, Val Loss: 1.8090, Val Accuracy: 0.7520

Validation Examples:
Question: 2112+3381 | True: 5493 | Predicted: 5493 | ✓
Question: 8828+3584 | True: 12412 | Predicted: 12412 | ✓
Question: 9665-1738 | True: 7927 | Predicted: 7927 | ✓
Question: 2527-2207 | True: 320 | Predicted: -320 | ✗
Question: 468-4045 | True: -3577 | Predicted: -2877 | ✗

Epoch 62/250:
Train Loss: 1.8481, Train Accuracy: 0.6081, Val Loss: 1.8066, Val Accuracy: 0.7468
Epoch 63/250:
Train Loss: 1.8469, Train Accuracy: 0.6150, Val Loss: 1.8083, Val Accuracy: 0.7455
Epoch 64/250:
Train Loss: 1.8442, Train Accuracy: 0.6225, Val Loss: 1.8077, Val Accuracy: 0.7475
Epoch 65/250:
Train Loss: 1.8426, Train Accuracy: 0.6228, Val Loss: 1.8110, Val Accuracy: 0.7388
Epoch 66/250:
Train Loss: 1.8396, Train Accuracy: 0.6337, Val Loss: 1.8045, Val Accuracy: 0.7505

Validation Examples:
Question: 8476-6124 | True: 2352 | Predicted: 2352 | ✓
Question: 5386-7287 | True: -1901 | Predicted: -1901 | ✓
Question: 5851+6943 | True: 12794 | Predicted: 12794 | ✓
Question: 7223+846 | True: 8069 | Predicted: 8069 | ✓
Question: 6439+1478 | True: 7917 | Predicted: 7917 | ✓

Epoch 67/250:
Train Loss: 1.8389, Train Accuracy: 0.6351, Val Loss: 1.8078, Val Accuracy: 0.7488
Epoch 68/250:
Train Loss: 1.8383, Train Accuracy: 0.6388, Val Loss: 1.8059, Val Accuracy: 0.7512
Epoch 69/250:
Train Loss: 1.8363, Train Accuracy: 0.6434, Val Loss: 1.8075, Val Accuracy: 0.7495
Epoch 70/250:
Train Loss: 1.8349, Train Accuracy: 0.6486, Val Loss: 1.8038, Val Accuracy: 0.7538
Epoch 71/250:
Train Loss: 1.8352, Train Accuracy: 0.6481, Val Loss: 1.8026, Val Accuracy: 0.7615

Validation Examples:
Question: 3699+2800 | True: 6499 | Predicted: 6499 | ✓
Question: 8021-8099 | True: -78 | Predicted: -118 | ✗
Question: 3024-3176 | True: -152 | Predicted: -122 | ✗
Question: 3474-5435 | True: -1961 | Predicted: -1061 | ✗
Question: 9892+6970 | True: 16862 | Predicted: 16862 | ✓

Epoch 72/250:
Train Loss: 1.8315, Train Accuracy: 0.6611, Val Loss: 1.8034, Val Accuracy: 0.7550
Epoch 73/250:
Train Loss: 1.8307, Train Accuracy: 0.6610, Val Loss: 1.8044, Val Accuracy: 0.7570
Epoch 74/250:
Train Loss: 1.8288, Train Accuracy: 0.6644, Val Loss: 1.7985, Val Accuracy: 0.7652
Epoch 75/250:
Train Loss: 1.8274, Train Accuracy: 0.6687, Val Loss: 1.8032, Val Accuracy: 0.7542
Epoch 76/250:
Train Loss: 1.8284, Train Accuracy: 0.6677, Val Loss: 1.7970, Val Accuracy: 0.7730

Validation Examples:
Question: 9597-6593 | True: 3004 | Predicted: 2004 | ✗
Question: 2512+6751 | True: 9263 | Predicted: 9263 | ✓
Question: 1414+2856 | True: 4270 | Predicted: 4270 | ✓
Question: 4592-8376 | True: -3784 | Predicted: -3784 | ✓
Question: 3528-5605 | True: -2077 | Predicted: -2087 | ✗

Epoch 77/250:
Train Loss: 1.8271, Train Accuracy: 0.6734, Val Loss: 1.7976, Val Accuracy: 0.7742
Epoch 78/250:
Train Loss: 1.8253, Train Accuracy: 0.6758, Val Loss: 1.8049, Val Accuracy: 0.7568
Epoch 79/250:
Train Loss: 1.8257, Train Accuracy: 0.6777, Val Loss: 1.7981, Val Accuracy: 0.7668
Epoch 80/250:
Train Loss: 1.8232, Train Accuracy: 0.6815, Val Loss: 1.8012, Val Accuracy: 0.7592
Epoch 81/250:
Train Loss: 1.8211, Train Accuracy: 0.6861, Val Loss: 1.7966, Val Accuracy: 0.7728

Validation Examples:
Question: 9770+5738 | True: 15508 | Predicted: 15508 | ✓
Question: 8688-1442 | True: 7246 | Predicted: 7246 | ✓
Question: 102-1002 | True: -900 | Predicted: -8000 | ✗
Question: 6551-4981 | True: 1570 | Predicted: 1570 | ✓
Question: 9862-8659 | True: 1203 | Predicted: 1203 | ✓

Epoch 82/250:
Train Loss: 1.8217, Train Accuracy: 0.6860, Val Loss: 1.7974, Val Accuracy: 0.7742
Epoch 83/250:
Train Loss: 1.8203, Train Accuracy: 0.6869, Val Loss: 1.7964, Val Accuracy: 0.7695
Epoch 84/250:
Train Loss: 1.8195, Train Accuracy: 0.6897, Val Loss: 1.7955, Val Accuracy: 0.7758
Epoch 85/250:
Train Loss: 1.8189, Train Accuracy: 0.6894, Val Loss: 1.7928, Val Accuracy: 0.7760
Epoch 86/250:
Train Loss: 1.8179, Train Accuracy: 0.6933, Val Loss: 1.7917, Val Accuracy: 0.7802

Validation Examples:
Question: 4757-7396 | True: -2639 | Predicted: -2639 | ✓
Question: 9120-9010 | True: 110 | Predicted: 2988 | ✗
Question: 3914-3206 | True: 708 | Predicted: 2708 | ✗
Question: 7564+4824 | True: 12388 | Predicted: 12388 | ✓
Question: 7956-7794 | True: 162 | Predicted: -162 | ✗

Epoch 87/250:
Train Loss: 1.8158, Train Accuracy: 0.6987, Val Loss: 1.7944, Val Accuracy: 0.7725
Epoch 88/250:
Train Loss: 1.8151, Train Accuracy: 0.6983, Val Loss: 1.7912, Val Accuracy: 0.7850
Epoch 89/250:
Train Loss: 1.8153, Train Accuracy: 0.6960, Val Loss: 1.7932, Val Accuracy: 0.7778
Epoch 90/250:
Train Loss: 1.8133, Train Accuracy: 0.7021, Val Loss: 1.7900, Val Accuracy: 0.7785
Epoch 91/250:
Train Loss: 1.8145, Train Accuracy: 0.6982, Val Loss: 1.7918, Val Accuracy: 0.7800

Validation Examples:
Question: 1412-1150 | True: 262 | Predicted: 2232 | ✗
Question: 2407-3824 | True: -1417 | Predicted: -1417 | ✓
Question: 3714-7975 | True: -4261 | Predicted: -4261 | ✓
Question: 5789+678 | True: 6467 | Predicted: 6467 | ✓
Question: 3326-1068 | True: 2258 | Predicted: 2258 | ✓

Epoch 92/250:
Train Loss: 1.8128, Train Accuracy: 0.7025, Val Loss: 1.7918, Val Accuracy: 0.7808
Epoch 93/250:
Train Loss: 1.8121, Train Accuracy: 0.7036, Val Loss: 1.7869, Val Accuracy: 0.7877
Epoch 94/250:
Train Loss: 1.8107, Train Accuracy: 0.7091, Val Loss: 1.7893, Val Accuracy: 0.7875
Epoch 95/250:
Train Loss: 1.8099, Train Accuracy: 0.7097, Val Loss: 1.7877, Val Accuracy: 0.7845
Epoch 96/250:
Train Loss: 1.8104, Train Accuracy: 0.7079, Val Loss: 1.7898, Val Accuracy: 0.7860

Validation Examples:
Question: 3522-1400 | True: 2122 | Predicted: 2122 | ✓
Question: 39-6487 | True: -6448 | Predicted: -4437 | ✗
Question: 6034-8796 | True: -2762 | Predicted: -2762 | ✓
Question: 6758-8447 | True: -1689 | Predicted: -1689 | ✓
Question: 8455+1023 | True: 9478 | Predicted: 9478 | ✓

Epoch 97/250:
Train Loss: 1.8095, Train Accuracy: 0.7100, Val Loss: 1.7892, Val Accuracy: 0.7827
Epoch 98/250:
Train Loss: 1.8094, Train Accuracy: 0.7117, Val Loss: 1.7906, Val Accuracy: 0.7835
Epoch 99/250:
Train Loss: 1.8079, Train Accuracy: 0.7119, Val Loss: 1.7872, Val Accuracy: 0.7917
Epoch 100/250:
Train Loss: 1.8070, Train Accuracy: 0.7202, Val Loss: 1.7837, Val Accuracy: 0.7957
Epoch 101/250:
Train Loss: 1.8050, Train Accuracy: 0.7202, Val Loss: 1.7860, Val Accuracy: 0.7915

Validation Examples:
Question: 6808+1114 | True: 7922 | Predicted: 7922 | ✓
Question: 1111-9698 | True: -8587 | Predicted: -8587 | ✓
Question: 4560-5119 | True: -559 | Predicted: -453 | ✗
Question: 180-5103 | True: -4923 | Predicted: -4233 | ✗
Question: 8363-7320 | True: 1043 | Predicted: 1043 | ✓

Epoch 102/250:
Train Loss: 1.8048, Train Accuracy: 0.7223, Val Loss: 1.7841, Val Accuracy: 0.7913
Epoch 103/250:
Train Loss: 1.8034, Train Accuracy: 0.7215, Val Loss: 1.7828, Val Accuracy: 0.7955
Epoch 104/250:
Train Loss: 1.8034, Train Accuracy: 0.7203, Val Loss: 1.7822, Val Accuracy: 0.7917
Epoch 105/250:
Train Loss: 1.8013, Train Accuracy: 0.7294, Val Loss: 1.7802, Val Accuracy: 0.8000
Epoch 106/250:
Train Loss: 1.8016, Train Accuracy: 0.7268, Val Loss: 1.7801, Val Accuracy: 0.8013

Validation Examples:
Question: 4354+2132 | True: 6486 | Predicted: 6486 | ✓
Question: 9174+1205 | True: 10379 | Predicted: 10379 | ✓
Question: 6625-5878 | True: 747 | Predicted: 8747 | ✗
Question: 8959-3202 | True: 5757 | Predicted: 5757 | ✓
Question: 617-845 | True: -228 | Predicted: -828 | ✗

Epoch 107/250:
Train Loss: 1.8019, Train Accuracy: 0.7239, Val Loss: 1.7798, Val Accuracy: 0.7995
Epoch 108/250:
Train Loss: 1.7992, Train Accuracy: 0.7328, Val Loss: 1.7784, Val Accuracy: 0.8057
Epoch 109/250:
Train Loss: 1.7996, Train Accuracy: 0.7286, Val Loss: 1.7789, Val Accuracy: 0.8010
Epoch 110/250:
Train Loss: 1.7996, Train Accuracy: 0.7319, Val Loss: 1.7796, Val Accuracy: 0.8040
Epoch 111/250:
Train Loss: 1.7987, Train Accuracy: 0.7302, Val Loss: 1.7783, Val Accuracy: 0.8005

Validation Examples:
Question: 3064-77 | True: 2987 | Predicted: 2987 | ✓
Question: 8131+7320 | True: 15451 | Predicted: 15451 | ✓
Question: 6518+1556 | True: 8074 | Predicted: 8074 | ✓
Question: 1416-4596 | True: -3180 | Predicted: -3180 | ✓
Question: 6518+642 | True: 7160 | Predicted: 7160 | ✓

Epoch 112/250:
Train Loss: 1.7975, Train Accuracy: 0.7326, Val Loss: 1.7802, Val Accuracy: 0.8047
Epoch 113/250:
Train Loss: 1.7959, Train Accuracy: 0.7384, Val Loss: 1.7757, Val Accuracy: 0.8075
Epoch 114/250:
Train Loss: 1.7960, Train Accuracy: 0.7389, Val Loss: 1.7774, Val Accuracy: 0.8067
Epoch 115/250:
Train Loss: 1.7943, Train Accuracy: 0.7412, Val Loss: 1.7763, Val Accuracy: 0.8197
Epoch 116/250:
Train Loss: 1.7945, Train Accuracy: 0.7425, Val Loss: 1.7734, Val Accuracy: 0.8193

Validation Examples:
Question: 6240+5980 | True: 12220 | Predicted: 12220 | ✓
Question: 3116-2493 | True: 623 | Predicted: 8623 | ✗
Question: 1658-2350 | True: -692 | Predicted: -699 | ✗
Question: 1987-7899 | True: -5912 | Predicted: -5912 | ✓
Question: 8117-620 | True: 7497 | Predicted: 7497 | ✓

Epoch 117/250:
Train Loss: 1.7918, Train Accuracy: 0.7505, Val Loss: 1.7726, Val Accuracy: 0.8243
Epoch 118/250:
Train Loss: 1.7922, Train Accuracy: 0.7498, Val Loss: 1.7737, Val Accuracy: 0.8180
Epoch 119/250:
Train Loss: 1.7918, Train Accuracy: 0.7475, Val Loss: 1.7766, Val Accuracy: 0.8153
Epoch 120/250:
Train Loss: 1.7917, Train Accuracy: 0.7493, Val Loss: 1.7710, Val Accuracy: 0.8220
Epoch 121/250:
Train Loss: 1.7921, Train Accuracy: 0.7455, Val Loss: 1.7740, Val Accuracy: 0.8165

Validation Examples:
Question: 8482+8270 | True: 16752 | Predicted: 16752 | ✓
Question: 377-2588 | True: -2211 | Predicted: -2811 | ✗
Question: 2458+4193 | True: 6651 | Predicted: 6651 | ✓
Question: 7726-8708 | True: -982 | Predicted: -0982 | ✗
Question: 6387-9672 | True: -3285 | Predicted: -3285 | ✓

Epoch 122/250:
Train Loss: 1.7918, Train Accuracy: 0.7487, Val Loss: 1.7706, Val Accuracy: 0.8270
Epoch 123/250:
Train Loss: 1.7904, Train Accuracy: 0.7512, Val Loss: 1.7691, Val Accuracy: 0.8263
Epoch 124/250:
Train Loss: 1.7890, Train Accuracy: 0.7552, Val Loss: 1.7717, Val Accuracy: 0.8263
Epoch 125/250:
Train Loss: 1.7882, Train Accuracy: 0.7595, Val Loss: 1.7693, Val Accuracy: 0.8325
Epoch 126/250:
Train Loss: 1.7876, Train Accuracy: 0.7585, Val Loss: 1.7701, Val Accuracy: 0.8225

Validation Examples:
Question: 9109+8187 | True: 17296 | Predicted: 17296 | ✓
Question: 7757+6935 | True: 14692 | Predicted: 14692 | ✓
Question: 6163+2951 | True: 9114 | Predicted: 9114 | ✓
Question: 8094+1985 | True: 10079 | Predicted: 1079 | ✗
Question: 4648+4889 | True: 9537 | Predicted: 9537 | ✓

Epoch 127/250:
Train Loss: 1.7877, Train Accuracy: 0.7595, Val Loss: 1.7692, Val Accuracy: 0.8315
Epoch 128/250:
Train Loss: 1.7867, Train Accuracy: 0.7615, Val Loss: 1.7740, Val Accuracy: 0.8163
Epoch 129/250:
Train Loss: 1.7867, Train Accuracy: 0.7607, Val Loss: 1.7705, Val Accuracy: 0.8240
Epoch 130/250:
Train Loss: 1.7872, Train Accuracy: 0.7563, Val Loss: 1.7691, Val Accuracy: 0.8303
Epoch 131/250:
Train Loss: 1.7869, Train Accuracy: 0.7604, Val Loss: 1.7684, Val Accuracy: 0.8297

Validation Examples:
Question: 1885-4702 | True: -2817 | Predicted: -2817 | ✓
Question: 8253+7305 | True: 15558 | Predicted: 15558 | ✓
Question: 895-2592 | True: -1697 | Predicted: -1377 | ✗
Question: 7016+9520 | True: 16536 | Predicted: 16536 | ✓
Question: 7243-7060 | True: 183 | Predicted: 1727 | ✗

Epoch 132/250:
Train Loss: 1.7869, Train Accuracy: 0.7584, Val Loss: 1.7684, Val Accuracy: 0.8303
Epoch 133/250:
Train Loss: 1.7859, Train Accuracy: 0.7644, Val Loss: 1.7674, Val Accuracy: 0.8305
Epoch 134/250:
Train Loss: 1.7852, Train Accuracy: 0.7622, Val Loss: 1.7673, Val Accuracy: 0.8330
Epoch 135/250:
Train Loss: 1.7832, Train Accuracy: 0.7679, Val Loss: 1.7656, Val Accuracy: 0.8347
Epoch 136/250:
Train Loss: 1.7837, Train Accuracy: 0.7652, Val Loss: 1.7687, Val Accuracy: 0.8310

Validation Examples:
Question: 1949+6985 | True: 8934 | Predicted: 8934 | ✓
Question: 1984-2056 | True: -72 | Predicted: -077 | ✗
Question: 3403-6269 | True: -2866 | Predicted: -2866 | ✓
Question: 3921+1200 | True: 5121 | Predicted: 5121 | ✓
Question: 9118-8411 | True: 707 | Predicted: 8707 | ✗

Epoch 137/250:
Train Loss: 1.7834, Train Accuracy: 0.7674, Val Loss: 1.7681, Val Accuracy: 0.8317
Epoch 138/250:
Train Loss: 1.7827, Train Accuracy: 0.7690, Val Loss: 1.7707, Val Accuracy: 0.8285
Epoch 139/250:
Train Loss: 1.7831, Train Accuracy: 0.7706, Val Loss: 1.7649, Val Accuracy: 0.8345
Epoch 140/250:
Train Loss: 1.7820, Train Accuracy: 0.7713, Val Loss: 1.7678, Val Accuracy: 0.8253
Epoch 141/250:
Train Loss: 1.7838, Train Accuracy: 0.7652, Val Loss: 1.7718, Val Accuracy: 0.8200

Validation Examples:
Question: 7605-6572 | True: 1033 | Predicted: 1033 | ✓
Question: 1922+1840 | True: 3762 | Predicted: 3762 | ✓
Question: 5686-1221 | True: 4465 | Predicted: 4465 | ✓
Question: 5443+9179 | True: 14622 | Predicted: 14622 | ✓
Question: 806+7894 | True: 8700 | Predicted: 8700 | ✓

Epoch 142/250:
Train Loss: 1.7842, Train Accuracy: 0.7658, Val Loss: 1.7663, Val Accuracy: 0.8355
Epoch 143/250:
Train Loss: 1.7813, Train Accuracy: 0.7724, Val Loss: 1.7639, Val Accuracy: 0.8347
Epoch 144/250:
Train Loss: 1.7812, Train Accuracy: 0.7724, Val Loss: 1.7665, Val Accuracy: 0.8335
Epoch 145/250:
Train Loss: 1.7804, Train Accuracy: 0.7740, Val Loss: 1.7658, Val Accuracy: 0.8305
Epoch 146/250:
Train Loss: 1.7797, Train Accuracy: 0.7753, Val Loss: 1.7640, Val Accuracy: 0.8323

Validation Examples:
Question: 3653-4168 | True: -515 | Predicted: -515 | ✓
Question: 4998+7793 | True: 12791 | Predicted: 12791 | ✓
Question: 6333-7326 | True: -993 | Predicted: -193 | ✗
Question: 8027-6731 | True: 1296 | Predicted: 1296 | ✓
Question: 7408-7541 | True: -133 | Predicted: -143 | ✗

Epoch 147/250:
Train Loss: 1.7781, Train Accuracy: 0.7787, Val Loss: 1.7654, Val Accuracy: 0.8317
Epoch 148/250:
Train Loss: 1.7765, Train Accuracy: 0.7817, Val Loss: 1.7631, Val Accuracy: 0.8345
Epoch 149/250:
Train Loss: 1.7773, Train Accuracy: 0.7770, Val Loss: 1.7620, Val Accuracy: 0.8333
Epoch 150/250:
Train Loss: 1.7781, Train Accuracy: 0.7742, Val Loss: 1.7647, Val Accuracy: 0.8297
Epoch 151/250:
Train Loss: 1.7778, Train Accuracy: 0.7751, Val Loss: 1.7623, Val Accuracy: 0.8350

Validation Examples:
Question: 5002+2275 | True: 7277 | Predicted: 7277 | ✓
Question: 7012+9313 | True: 16325 | Predicted: 16325 | ✓
Question: 7440+6452 | True: 13892 | Predicted: 13892 | ✓
Question: 8449-7304 | True: 1145 | Predicted: 1145 | ✓
Question: 2018-3544 | True: -1526 | Predicted: -1526 | ✓

Epoch 152/250:
Train Loss: 1.7760, Train Accuracy: 0.7783, Val Loss: 1.7608, Val Accuracy: 0.8405
Epoch 153/250:
Train Loss: 1.7755, Train Accuracy: 0.7823, Val Loss: 1.7602, Val Accuracy: 0.8390
Epoch 154/250:
Train Loss: 1.7763, Train Accuracy: 0.7774, Val Loss: 1.7625, Val Accuracy: 0.8343
Epoch 155/250:
Train Loss: 1.7756, Train Accuracy: 0.7817, Val Loss: 1.7622, Val Accuracy: 0.8367
Epoch 156/250:
Train Loss: 1.7756, Train Accuracy: 0.7819, Val Loss: 1.7620, Val Accuracy: 0.8390

Validation Examples:
Question: 5487+4047 | True: 9534 | Predicted: 9534 | ✓
Question: 7976+1545 | True: 9521 | Predicted: 9521 | ✓
Question: 2306+2612 | True: 4918 | Predicted: 4918 | ✓
Question: 390-7305 | True: -6915 | Predicted: -6115 | ✗
Question: 9145+1800 | True: 10945 | Predicted: 10945 | ✓

Epoch 157/250:
Train Loss: 1.7740, Train Accuracy: 0.7842, Val Loss: 1.7621, Val Accuracy: 0.8335
Epoch 158/250:
Train Loss: 1.7747, Train Accuracy: 0.7830, Val Loss: 1.7594, Val Accuracy: 0.8405
Epoch 159/250:
Train Loss: 1.7751, Train Accuracy: 0.7796, Val Loss: 1.7627, Val Accuracy: 0.8290
Epoch 160/250:
Train Loss: 1.7743, Train Accuracy: 0.7825, Val Loss: 1.7594, Val Accuracy: 0.8387
Epoch 161/250:
Train Loss: 1.7736, Train Accuracy: 0.7833, Val Loss: 1.7608, Val Accuracy: 0.8355

Validation Examples:
Question: 8103+6493 | True: 14596 | Predicted: 14596 | ✓
Question: 9585+3149 | True: 12734 | Predicted: 12734 | ✓
Question: 3811-6103 | True: -2292 | Predicted: -2292 | ✓
Question: 4576-4146 | True: 430 | Predicted: 2560 | ✗
Question: 6200-3362 | True: 2838 | Predicted: 2838 | ✓

Epoch 162/250:
Train Loss: 1.7731, Train Accuracy: 0.7879, Val Loss: 1.7611, Val Accuracy: 0.8403
Epoch 163/250:
Train Loss: 1.7759, Train Accuracy: 0.7809, Val Loss: 1.7600, Val Accuracy: 0.8385
Epoch 164/250:
Train Loss: 1.7727, Train Accuracy: 0.7866, Val Loss: 1.7600, Val Accuracy: 0.8407
Epoch 165/250:
Train Loss: 1.7722, Train Accuracy: 0.7887, Val Loss: 1.7592, Val Accuracy: 0.8393
Epoch 166/250:
Train Loss: 1.7712, Train Accuracy: 0.7901, Val Loss: 1.7609, Val Accuracy: 0.8333

Validation Examples:
Question: 2777-4695 | True: -1918 | Predicted: -1918 | ✓
Question: 8455+1023 | True: 9478 | Predicted: 9478 | ✓
Question: 7105-5738 | True: 1367 | Predicted: 1367 | ✓
Question: 6456+4340 | True: 10796 | Predicted: 10796 | ✓
Question: 2654+8375 | True: 11029 | Predicted: 11029 | ✓

Epoch 167/250:
Train Loss: 1.7709, Train Accuracy: 0.7882, Val Loss: 1.7574, Val Accuracy: 0.8413
Epoch 168/250:
Train Loss: 1.7705, Train Accuracy: 0.7914, Val Loss: 1.7592, Val Accuracy: 0.8365
Epoch 169/250:
Train Loss: 1.7698, Train Accuracy: 0.7923, Val Loss: 1.7595, Val Accuracy: 0.8345
Epoch 170/250:
Train Loss: 1.7706, Train Accuracy: 0.7874, Val Loss: 1.7584, Val Accuracy: 0.8360
Epoch 171/250:
Train Loss: 1.7708, Train Accuracy: 0.7857, Val Loss: 1.7570, Val Accuracy: 0.8410

Validation Examples:
Question: 7594+452 | True: 8046 | Predicted: 7046 | ✗
Question: 2504-2169 | True: 335 | Predicted: 1365 | ✗
Question: 6361-7259 | True: -898 | Predicted: -894 | ✗
Question: 4162+1654 | True: 5816 | Predicted: 5816 | ✓
Question: 269+9484 | True: 9753 | Predicted: 9753 | ✓

Epoch 172/250:
Train Loss: 1.7704, Train Accuracy: 0.7894, Val Loss: 1.7558, Val Accuracy: 0.8468
Epoch 173/250:
Train Loss: 1.7701, Train Accuracy: 0.7917, Val Loss: 1.7573, Val Accuracy: 0.8420
Epoch 174/250:
Train Loss: 1.7693, Train Accuracy: 0.7921, Val Loss: 1.7566, Val Accuracy: 0.8440
Epoch 175/250:
Train Loss: 1.7687, Train Accuracy: 0.7935, Val Loss: 1.7580, Val Accuracy: 0.8397
Epoch 176/250:
Train Loss: 1.7693, Train Accuracy: 0.7912, Val Loss: 1.7588, Val Accuracy: 0.8350

Validation Examples:
Question: 1957-2716 | True: -759 | Predicted: -759 | ✓
Question: 2572-9361 | True: -6789 | Predicted: -6789 | ✓
Question: 2337-5182 | True: -2845 | Predicted: -2845 | ✓
Question: 8491-8539 | True: -48 | Predicted: -048 | ✗
Question: 8548-8329 | True: 219 | Predicted: 1789 | ✗

Epoch 177/250:
Train Loss: 1.7687, Train Accuracy: 0.7934, Val Loss: 1.7556, Val Accuracy: 0.8455
Epoch 178/250:
Train Loss: 1.7684, Train Accuracy: 0.7940, Val Loss: 1.7572, Val Accuracy: 0.8417
Epoch 179/250:
Train Loss: 1.7683, Train Accuracy: 0.7939, Val Loss: 1.7558, Val Accuracy: 0.8427
Epoch 180/250:
Train Loss: 1.7687, Train Accuracy: 0.7942, Val Loss: 1.7584, Val Accuracy: 0.8350
Epoch 181/250:
Train Loss: 1.7682, Train Accuracy: 0.7959, Val Loss: 1.7588, Val Accuracy: 0.8375

Validation Examples:
Question: 282+4661 | True: 4943 | Predicted: 4943 | ✓
Question: 2014-736 | True: 1278 | Predicted: 1278 | ✓
Question: 298-9152 | True: -8854 | Predicted: -8554 | ✗
Question: 5176-2310 | True: 2866 | Predicted: 2866 | ✓
Question: 6954-5646 | True: 1308 | Predicted: 1308 | ✓

Epoch 182/250:
Train Loss: 1.7671, Train Accuracy: 0.7963, Val Loss: 1.7543, Val Accuracy: 0.8482
Epoch 183/250:
Train Loss: 1.7683, Train Accuracy: 0.7961, Val Loss: 1.7597, Val Accuracy: 0.8403
Epoch 184/250:
Train Loss: 1.7669, Train Accuracy: 0.7989, Val Loss: 1.7533, Val Accuracy: 0.8502
Epoch 185/250:
Train Loss: 1.7662, Train Accuracy: 0.7992, Val Loss: 1.7567, Val Accuracy: 0.8387
Epoch 186/250:
Train Loss: 1.7659, Train Accuracy: 0.8026, Val Loss: 1.7538, Val Accuracy: 0.8485

Validation Examples:
Question: 3218+1332 | True: 4550 | Predicted: 4550 | ✓
Question: 8477+7694 | True: 16171 | Predicted: 16171 | ✓
Question: 9890+4036 | True: 13926 | Predicted: 13926 | ✓
Question: 4513-6837 | True: -2324 | Predicted: -2324 | ✓
Question: 367-8504 | True: -8137 | Predicted: -8337 | ✗

Epoch 187/250:
Train Loss: 1.7649, Train Accuracy: 0.8036, Val Loss: 1.7555, Val Accuracy: 0.8468
Epoch 188/250:
Train Loss: 1.7654, Train Accuracy: 0.8011, Val Loss: 1.7571, Val Accuracy: 0.8395
Epoch 189/250:
Train Loss: 1.7657, Train Accuracy: 0.8004, Val Loss: 1.7545, Val Accuracy: 0.8438
Epoch 190/250:
Train Loss: 1.7640, Train Accuracy: 0.8033, Val Loss: 1.7531, Val Accuracy: 0.8528
Epoch 191/250:
Train Loss: 1.7634, Train Accuracy: 0.8063, Val Loss: 1.7524, Val Accuracy: 0.8538

Validation Examples:
Question: 7605-6572 | True: 1033 | Predicted: 1033 | ✓
Question: 711+8986 | True: 9697 | Predicted: 9697 | ✓
Question: 2340+8550 | True: 10890 | Predicted: 10890 | ✓
Question: 8306+6900 | True: 15206 | Predicted: 15206 | ✓
Question: 2436-8478 | True: -6042 | Predicted: -6042 | ✓

Epoch 192/250:
Train Loss: 1.7658, Train Accuracy: 0.7997, Val Loss: 1.7543, Val Accuracy: 0.8468
Epoch 193/250:
Train Loss: 1.7638, Train Accuracy: 0.8069, Val Loss: 1.7534, Val Accuracy: 0.8485
Epoch 194/250:
Train Loss: 1.7636, Train Accuracy: 0.8050, Val Loss: 1.7527, Val Accuracy: 0.8542
Epoch 195/250:
Train Loss: 1.7632, Train Accuracy: 0.8061, Val Loss: 1.7526, Val Accuracy: 0.8525
Epoch 196/250:
Train Loss: 1.7618, Train Accuracy: 0.8110, Val Loss: 1.7519, Val Accuracy: 0.8578

Validation Examples:
Question: 4504-555 | True: 3949 | Predicted: 3949 | ✓
Question: 959-9611 | True: -8652 | Predicted: -8552 | ✗
Question: 6682+7948 | True: 14630 | Predicted: 14630 | ✓
Question: 3049-9647 | True: -6598 | Predicted: -6698 | ✗
Question: 4446-3053 | True: 1393 | Predicted: 1393 | ✓

Epoch 197/250:
Train Loss: 1.7642, Train Accuracy: 0.8026, Val Loss: 1.7519, Val Accuracy: 0.8555
Epoch 198/250:
Train Loss: 1.7650, Train Accuracy: 0.8030, Val Loss: 1.7560, Val Accuracy: 0.8450
Epoch 199/250:
Train Loss: 1.7630, Train Accuracy: 0.8070, Val Loss: 1.7531, Val Accuracy: 0.8515
Epoch 200/250:
Train Loss: 1.7614, Train Accuracy: 0.8113, Val Loss: 1.7511, Val Accuracy: 0.8552
Epoch 201/250:
Train Loss: 1.7630, Train Accuracy: 0.8079, Val Loss: 1.7523, Val Accuracy: 0.8515

Validation Examples:
Question: 3666+9401 | True: 13067 | Predicted: 13067 | ✓
Question: 3290+7122 | True: 10412 | Predicted: 10412 | ✓
Question: 8828+3584 | True: 12412 | Predicted: 12412 | ✓
Question: 3545-593 | True: 2952 | Predicted: 2952 | ✓
Question: 9358+2583 | True: 11941 | Predicted: 11941 | ✓

Epoch 202/250:
Train Loss: 1.7631, Train Accuracy: 0.8061, Val Loss: 1.7521, Val Accuracy: 0.8518
Epoch 203/250:
Train Loss: 1.7621, Train Accuracy: 0.8100, Val Loss: 1.7506, Val Accuracy: 0.8575
Epoch 204/250:
Train Loss: 1.7616, Train Accuracy: 0.8120, Val Loss: 1.7518, Val Accuracy: 0.8538
Epoch 205/250:
Train Loss: 1.7621, Train Accuracy: 0.8104, Val Loss: 1.7527, Val Accuracy: 0.8530
Epoch 206/250:
Train Loss: 1.7613, Train Accuracy: 0.8138, Val Loss: 1.7507, Val Accuracy: 0.8568

Validation Examples:
Question: 420+3095 | True: 3515 | Predicted: 3515 | ✓
Question: 249+4477 | True: 4726 | Predicted: 4726 | ✓
Question: 9478-9435 | True: 43 | Predicted: -957 | ✗
Question: 791+3661 | True: 4452 | Predicted: 4452 | ✓
Question: 7601+5765 | True: 13366 | Predicted: 13366 | ✓

Epoch 207/250:
Train Loss: 1.7628, Train Accuracy: 0.8080, Val Loss: 1.7537, Val Accuracy: 0.8475
Epoch 208/250:
Train Loss: 1.7627, Train Accuracy: 0.8096, Val Loss: 1.7522, Val Accuracy: 0.8560
Epoch 209/250:
Train Loss: 1.7614, Train Accuracy: 0.8119, Val Loss: 1.7528, Val Accuracy: 0.8515
Epoch 210/250:
Train Loss: 1.7606, Train Accuracy: 0.8140, Val Loss: 1.7537, Val Accuracy: 0.8482
Epoch 211/250:
Train Loss: 1.7615, Train Accuracy: 0.8114, Val Loss: 1.7512, Val Accuracy: 0.8550

Validation Examples:
Question: 2005-703 | True: 1302 | Predicted: 1302 | ✓
Question: 8662-5208 | True: 3454 | Predicted: 3454 | ✓
Question: 7808-7162 | True: 646 | Predicted: 2646 | ✗
Question: 138+133 | True: 271 | Predicted: 127 | ✗
Question: 9027-5509 | True: 3518 | Predicted: 3518 | ✓

Epoch 212/250:
Train Loss: 1.7599, Train Accuracy: 0.8149, Val Loss: 1.7502, Val Accuracy: 0.8598
Epoch 213/250:
Train Loss: 1.7623, Train Accuracy: 0.8089, Val Loss: 1.7518, Val Accuracy: 0.8528
Epoch 214/250:
Train Loss: 1.7620, Train Accuracy: 0.8101, Val Loss: 1.7543, Val Accuracy: 0.8495
Epoch 215/250:
Train Loss: 1.7602, Train Accuracy: 0.8141, Val Loss: 1.7511, Val Accuracy: 0.8585
Epoch 216/250:
Train Loss: 1.7594, Train Accuracy: 0.8175, Val Loss: 1.7507, Val Accuracy: 0.8565

Validation Examples:
Question: 273+8492 | True: 8765 | Predicted: 8765 | ✓
Question: 1738+7944 | True: 9682 | Predicted: 9682 | ✓
Question: 4012-8082 | True: -4070 | Predicted: -4070 | ✓
Question: 2524+730 | True: 3254 | Predicted: 3254 | ✓
Question: 5226-5907 | True: -681 | Predicted: -671 | ✗

Epoch 217/250:
Train Loss: 1.7605, Train Accuracy: 0.8145, Val Loss: 1.7509, Val Accuracy: 0.8548
Epoch 218/250:
Train Loss: 1.7617, Train Accuracy: 0.8097, Val Loss: 1.7500, Val Accuracy: 0.8568
Epoch 219/250:
Train Loss: 1.7588, Train Accuracy: 0.8186, Val Loss: 1.7505, Val Accuracy: 0.8565
Epoch 220/250:
Train Loss: 1.7604, Train Accuracy: 0.8141, Val Loss: 1.7505, Val Accuracy: 0.8595
Epoch 221/250:
Train Loss: 1.7599, Train Accuracy: 0.8148, Val Loss: 1.7502, Val Accuracy: 0.8562

Validation Examples:
Question: 2106+6613 | True: 8719 | Predicted: 8719 | ✓
Question: 8483-1503 | True: 6980 | Predicted: 6980 | ✓
Question: 5385+3743 | True: 9128 | Predicted: 9128 | ✓
Question: 8786-8985 | True: -199 | Predicted: -299 | ✗
Question: 485+6134 | True: 6619 | Predicted: 6619 | ✓

Epoch 222/250:
Train Loss: 1.7595, Train Accuracy: 0.8162, Val Loss: 1.7505, Val Accuracy: 0.8585
Epoch 223/250:
Train Loss: 1.7606, Train Accuracy: 0.8154, Val Loss: 1.7538, Val Accuracy: 0.8535
Epoch 224/250:
Train Loss: 1.7612, Train Accuracy: 0.8106, Val Loss: 1.7493, Val Accuracy: 0.8595
Epoch 225/250:
Train Loss: 1.7586, Train Accuracy: 0.8181, Val Loss: 1.7506, Val Accuracy: 0.8568
Epoch 226/250:
Train Loss: 1.7591, Train Accuracy: 0.8174, Val Loss: 1.7509, Val Accuracy: 0.8555

Validation Examples:
Question: 2330-9136 | True: -6806 | Predicted: -6806 | ✓
Question: 17+2967 | True: 2984 | Predicted: 2984 | ✓
Question: 9888-1351 | True: 8537 | Predicted: 8537 | ✓
Question: 9100-5838 | True: 3262 | Predicted: 3262 | ✓
Question: 1966-5876 | True: -3910 | Predicted: -3910 | ✓

Epoch 227/250:
Train Loss: 1.7582, Train Accuracy: 0.8202, Val Loss: 1.7496, Val Accuracy: 0.8568
Epoch 228/250:
Train Loss: 1.7594, Train Accuracy: 0.8142, Val Loss: 1.7502, Val Accuracy: 0.8545
Epoch 229/250:
Train Loss: 1.7589, Train Accuracy: 0.8172, Val Loss: 1.7487, Val Accuracy: 0.8600
Epoch 230/250:
Train Loss: 1.7586, Train Accuracy: 0.8188, Val Loss: 1.7518, Val Accuracy: 0.8542
Epoch 231/250:
Train Loss: 1.7603, Train Accuracy: 0.8136, Val Loss: 1.7508, Val Accuracy: 0.8520

Validation Examples:
Question: 782+3272 | True: 4054 | Predicted: 4054 | ✓
Question: 8611-7782 | True: 829 | Predicted: 8829 | ✗
Question: 273+8492 | True: 8765 | Predicted: 8765 | ✓
Question: 2524+730 | True: 3254 | Predicted: 3254 | ✓
Question: 4449-9204 | True: -4755 | Predicted: -4755 | ✓

Epoch 232/250:
Train Loss: 1.7590, Train Accuracy: 0.8180, Val Loss: 1.7498, Val Accuracy: 0.8610
Epoch 233/250:
Train Loss: 1.7604, Train Accuracy: 0.8143, Val Loss: 1.7547, Val Accuracy: 0.8460
Epoch 234/250:
Train Loss: 1.7594, Train Accuracy: 0.8169, Val Loss: 1.7502, Val Accuracy: 0.8572
Epoch 235/250:
Train Loss: 1.7598, Train Accuracy: 0.8161, Val Loss: 1.7490, Val Accuracy: 0.8585
Epoch 236/250:
Train Loss: 1.7582, Train Accuracy: 0.8201, Val Loss: 1.7494, Val Accuracy: 0.8605

Validation Examples:
Question: 7315+861 | True: 8176 | Predicted: 8176 | ✓
Question: 8041-2394 | True: 5647 | Predicted: 5647 | ✓
Question: 5335+9732 | True: 15067 | Predicted: 15067 | ✓
Question: 4774-2030 | True: 2744 | Predicted: 2744 | ✓
Question: 3074-4680 | True: -1606 | Predicted: -1606 | ✓

Epoch 237/250:
Train Loss: 1.7579, Train Accuracy: 0.8197, Val Loss: 1.7501, Val Accuracy: 0.8588
Epoch 238/250:
Train Loss: 1.7564, Train Accuracy: 0.8258, Val Loss: 1.7493, Val Accuracy: 0.8602
Epoch 239/250:
Train Loss: 1.7571, Train Accuracy: 0.8225, Val Loss: 1.7518, Val Accuracy: 0.8558
Epoch 240/250:
Train Loss: 1.7577, Train Accuracy: 0.8224, Val Loss: 1.7503, Val Accuracy: 0.8558
Epoch 241/250:
Train Loss: 1.7596, Train Accuracy: 0.8171, Val Loss: 1.7520, Val Accuracy: 0.8518

Validation Examples:
Question: 1510+2015 | True: 3525 | Predicted: 3525 | ✓
Question: 7642-4903 | True: 2739 | Predicted: 2739 | ✓
Question: 9504+4764 | True: 14268 | Predicted: 14268 | ✓
Question: 5112+8033 | True: 13145 | Predicted: 13145 | ✓
Question: 3916-6927 | True: -3011 | Predicted: -3011 | ✓

Epoch 242/250:
Train Loss: 1.7574, Train Accuracy: 0.8229, Val Loss: 1.7495, Val Accuracy: 0.8578
Epoch 243/250:
Train Loss: 1.7569, Train Accuracy: 0.8223, Val Loss: 1.7494, Val Accuracy: 0.8568
Epoch 244/250:
Train Loss: 1.7577, Train Accuracy: 0.8209, Val Loss: 1.7500, Val Accuracy: 0.8588
Epoch 245/250:
Train Loss: 1.7592, Train Accuracy: 0.8171, Val Loss: 1.7497, Val Accuracy: 0.8560
Epoch 246/250:
Train Loss: 1.7578, Train Accuracy: 0.8207, Val Loss: 1.7507, Val Accuracy: 0.8548

Validation Examples:
Question: 3002+4666 | True: 7668 | Predicted: 7668 | ✓
Question: 5911-8098 | True: -2187 | Predicted: -2187 | ✓
Question: 1476+587 | True: 2063 | Predicted: 2063 | ✓
Question: 4460-6176 | True: -1716 | Predicted: -1716 | ✓
Question: 3360+1906 | True: 5266 | Predicted: 5266 | ✓

Epoch 247/250:
Train Loss: 1.7599, Train Accuracy: 0.8159, Val Loss: 1.7492, Val Accuracy: 0.8575
Epoch 248/250:
Train Loss: 1.7570, Train Accuracy: 0.8226, Val Loss: 1.7485, Val Accuracy: 0.8612
Epoch 249/250:
Train Loss: 1.7565, Train Accuracy: 0.8241, Val Loss: 1.7481, Val Accuracy: 0.8608
Epoch 250/250:
Train Loss: 1.7573, Train Accuracy: 0.8224, Val Loss: 1.7495, Val Accuracy: 0.8585
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Key Changes and Explanation:</p>
<p>Transformer Model:</p>
<p>Embedding Layer: Converts one-hot vectors to dense embeddings.</p>
<p>Positional Encoding: Adds positional information to the embeddings.positional encodings are crucial to incorporate sequence order which is not handled in the transformer's self attention.</p>
<p>Transformer Encoder: The core of the model, using multi-head self-attention to capture relationships between all positions at once, unlike the LSTM in your original model which was working sequentially. This makes the model way more powerful.</p>
<p>Output Layer: Projects the final transformer outputs back to the size of your character set.</p>
<p>Data generation and processing: remains largely the same.</p>
<p>Hyperparameter Tuning</p>
<p>Improved Attention: The multi-head self-attention allows for more nuanced understanding of the input tokens compared to the naive attention in the original code.</p>
<p>Parallel Processing: The transformer can be highly parallelized on GPU, which greatly speeds up training.</p>
<p>Better Representation: The Transformer excels at learning relationships between words/tokens (in this case characters), allowing it to better learn how to perform arithmetic.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-2:-A-language-translation-model-with-attention">Part 2: A language translation model with attention<a class="anchor-link" href="#Part-2:-A-language-translation-model-with-attention">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>In this part of the problem set we are going to implement a translation with a Sequence to Sequence Network and Attention model.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="0">
<li>Please go over the NLP From Scratch: Translation with a Sequence to Sequence Network and Attention <a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">tutorial</a>. This attention model is very similar to what was learned in class (Luong), but a bit different. What are the main differences between  Badahnau and Luong attention mechanisms?</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Similarities to Luong Attention (Discussed in Class)</p>
<p>Goal: Both attention mechanisms share the primary goal of allowing the decoder to focus on the relevant parts of the input sequence.</p>
<p>Context Vector: Both calculate a context vector by taking a weighted sum of the encoder's outputs, where the weights reflect the alignment between the decoder's current state and the encoder's states.</p>
<p>Softmax Normalization: They use softmax to normalize the attention scores into probability distribution, where the attention weights sum to one.</p>
<p>How This Code Differs from What You Might've Seen in Class</p>
<p>Bahdanau: The code explicitly uses the Bahdanau attention mechanism which uses a single layer MLP to calculate the alignment scores. Whereas Luong attention may involve a dot product, general, or concat product to calculate the alignment scores.</p>
<p>GRU Instead of LSTM: The code uses GRUs instead of LSTMs for the RNNs, but both are valid in seq2seq models. The math is also similar, therefore not causing a fundamental difference in results.</p>
<p>Weight Calculation: Bahdanau attention combines the decoder and encoder hidden states to produce the attention weights before passing into the GRU cell in the decoder, while some forms of Luong attention (i.e. dot product form) may calculate weights after the GRU cell.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.a) Using <code>!wget</code>, <code>!unzip</code> , download and extract the <a href="https://www.manythings.org/anki/">hebrew-english</a> sentence pairs text file to the Colab <code>content/</code>  folder (or local folder if not using Colab).
1.b) The <code>heb.txt</code> must be parsed and cleaned (see tutorial for requirements or change the code as you see fit).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>2.a) Use the tutorial example to build  and train a Hebrew to English translation model with attention (using the parameters in the code cell below). Apply the same <code>eng_prefixes</code> filter to limit the train/test data.<br/>
2.b) Evaluate your trained model randomly on 20 sentences.<br/>
2.c) Show the attention plot for 5 random sentences.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="3">
<li>Do you think this model performs well? Why or why not? What are its limitations/disadvantages? What would you do to improve it?</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="4">
<li>Using any neural network architecture of your liking, build  a model with the aim to beat the model in 2.a. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better.</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># use the following parameters:</span>
<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>SOLUTION:</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">### MISSING</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># In Colab:</span>
<span class="o">!</span>wget<span class="w"> </span>https://www.manythings.org/anki/heb-eng.zip
<span class="o">!</span>unzip<span class="w"> </span>heb-eng.zip<span class="w"> </span>-d<span class="w"> </span>data
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>--2025-02-02 13:54:27--  https://www.manythings.org/anki/heb-eng.zip
Resolving www.manythings.org (www.manythings.org)... 173.254.30.110
Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4466359 (4.3M) [application/zip]
Saving to: ‘heb-eng.zip’

heb-eng.zip         100%[===================&gt;]   4.26M  2.29MB/s    in 1.9s    

2025-02-02 13:54:31 (2.29 MB/s) - ‘heb-eng.zip’ saved [4466359/4466359]

Archive:  heb-eng.zip
  inflating: data/_about.txt         
  inflating: data/heb.txt            
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">unicode_literals</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="nb">open</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">class</span> <span class="nc">Lang</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">"SOS"</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">"EOS"</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Count SOS and EOS</span>

    <span class="k">def</span> <span class="nf">addSentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addWord</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Turn a Unicode string to plain ASCII, thanks to</span>
<span class="c1"># https://stackoverflow.com/a/518232/2809427</span>
<span class="k">def</span> <span class="nf">unicodeToAscii</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s1">'NFD'</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">category</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">'Mn'</span>
    <span class="p">)</span>

<span class="c1"># Lowercase, trim, and remove non-letter characters</span>
<span class="k">def</span> <span class="nf">normalizeString</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">unicodeToAscii</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"([.!?])"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" \1"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"[^a-zA-Z!?]+"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">readLangs</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Reading lines..."</span><span class="p">)</span>

    <span class="c1"># Read the file and split into lines</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'data/</span><span class="si">%s</span><span class="s1">.txt'</span> <span class="o">%</span> <span class="p">(</span><span class="n">lang2</span><span class="p">),</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span><span class="o">.</span>\
        <span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="c1"># Split every line into pairs and normalize</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Ensure the line has at least two parts</span>
            <span class="n">eng</span> <span class="o">=</span> <span class="n">normalizeString</span><span class="p">(</span><span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Normalize the English sentence</span>
            <span class="n">heb</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>  <span class="c1"># Keep the Hebrew sentence as is</span>
            <span class="n">pairs</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">eng</span><span class="p">,</span> <span class="n">heb</span><span class="p">))</span>





    <span class="c1"># Reverse pairs, make Lang instances</span>
    <span class="k">if</span> <span class="n">reverse</span><span class="p">:</span>
        <span class="n">pairs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">]</span>
        <span class="n">input_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang2</span><span class="p">)</span>
        <span class="n">output_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">input_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang1</span><span class="p">)</span>
        <span class="n">output_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">eng_prefixes</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">"i am "</span><span class="p">,</span> <span class="s2">"i m "</span><span class="p">,</span>
    <span class="s2">"he is"</span><span class="p">,</span> <span class="s2">"he s "</span><span class="p">,</span>
    <span class="s2">"she is"</span><span class="p">,</span> <span class="s2">"she s "</span><span class="p">,</span>
    <span class="s2">"you are"</span><span class="p">,</span> <span class="s2">"you re "</span><span class="p">,</span>
    <span class="s2">"we are"</span><span class="p">,</span> <span class="s2">"we re "</span><span class="p">,</span>
    <span class="s2">"they are"</span><span class="p">,</span> <span class="s2">"they re "</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">filterPair</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="ow">and</span> \
        <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="ow">and</span> \
        <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">eng_prefixes</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">filterPairs</span><span class="p">(</span><span class="n">pairs</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">pair</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span> <span class="k">if</span> <span class="n">filterPair</span><span class="p">(</span><span class="n">pair</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">prepareData</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">readLangs</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">,</span> <span class="n">reverse</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Read </span><span class="si">%s</span><span class="s2"> sentence pairs"</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">))</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="n">filterPairs</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Trimmed to </span><span class="si">%s</span><span class="s2"> sentence pairs"</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Counting words..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_lang</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">output_lang</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Counted words:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span>

<span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span><span class="s1">'eng'</span><span class="p">,</span> <span class="s1">'heb'</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pairs</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Reading lines...
Read 128133 sentence pairs
Trimmed to 9320 sentence pairs
Counting words...
Counted words:
heb 7519
eng 3067
['הם נפלאים.', 'they re gorgeous']
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">EncoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">DecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">,</span> <span class="n">target_tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">SOS_token</span><span class="p">)</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_step</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">)</span>
            <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">target_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Teacher forcing: Feed the target as the next input</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Teacher forcing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Without teacher forcing: use its own predictions as the next input</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># detach from history as input</span>

        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="kc">None</span> <span class="c1"># We return `None` for consistency in the training loop</span>

    <span class="k">def</span> <span class="nf">forward_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">BahdanauAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BahdanauAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wa</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ua</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Va</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">keys</span><span class="p">):</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Va</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wa</span><span class="p">(</span><span class="n">query</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ua</span><span class="p">(</span><span class="n">keys</span><span class="p">)))</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">keys</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">context</span><span class="p">,</span> <span class="n">weights</span>

<span class="k">class</span> <span class="nc">AttnDecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AttnDecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">BahdanauAttention</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">,</span> <span class="n">target_tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">SOS_token</span><span class="p">)</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">attentions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_step</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">)</span>
            <span class="n">attentions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">target_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Teacher forcing: Feed the target as the next input</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Teacher forcing</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Without teacher forcing: use its own predictions as the next input</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># detach from history as input</span>

        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attentions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attentions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">attentions</span>


    <span class="k">def</span> <span class="nf">forward_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>

        <span class="n">query</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">context</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="n">input_gru</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">input_gru</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">attn_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">indexesFromSentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">lang</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">tensorFromSentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="n">indexes</span> <span class="o">=</span> <span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
    <span class="n">indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">indexes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tensorsFromPair</span><span class="p">(</span><span class="n">pair</span><span class="p">):</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_dataloader</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span><span class="s1">'eng'</span><span class="p">,</span> <span class="s1">'heb'</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">target_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pairs</span><span class="p">):</span>
        <span class="n">inp_ids</span> <span class="o">=</span> <span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
        <span class="n">tgt_ids</span> <span class="o">=</span> <span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span>
        <span class="n">inp_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
        <span class="n">tgt_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
        <span class="n">input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">inp_ids</span><span class="p">)]</span> <span class="o">=</span> <span class="n">inp_ids</span>
        <span class="n">target_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_ids</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tgt_ids</span>

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                               <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

    <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">train_dataloader</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span>
          <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">data</span>

        <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
            <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">target_tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="k">def</span> <span class="nf">asMinutes</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="n">m</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="s1">'</span><span class="si">%d</span><span class="s1">m </span><span class="si">%d</span><span class="s1">s'</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">timeSince</span><span class="p">(</span><span class="n">since</span><span class="p">,</span> <span class="n">percent</span><span class="p">):</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">since</span>
    <span class="n">es</span> <span class="o">=</span> <span class="n">s</span> <span class="o">/</span> <span class="p">(</span><span class="n">percent</span><span class="p">)</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">es</span> <span class="o">-</span> <span class="n">s</span>
    <span class="k">return</span> <span class="s1">'</span><span class="si">%s</span><span class="s1"> (- </span><span class="si">%s</span><span class="s1">)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">asMinutes</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">asMinutes</span><span class="p">(</span><span class="n">rs</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
               <span class="n">print_every</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">plot_every</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">plot_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">print_loss_total</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Reset every print_every</span>
    <span class="n">plot_loss_total</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Reset every plot_every</span>

    <span class="n">encoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
        <span class="n">print_loss_total</span> <span class="o">+=</span> <span class="n">loss</span>
        <span class="n">plot_loss_total</span> <span class="o">+=</span> <span class="n">loss</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">print_loss_avg</span> <span class="o">=</span> <span class="n">print_loss_total</span> <span class="o">/</span> <span class="n">print_every</span>
            <span class="n">print_loss_total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">%s</span><span class="s1"> (</span><span class="si">%d</span><span class="s1"> </span><span class="si">%d%%</span><span class="s1">) </span><span class="si">%.4f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">timeSince</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">/</span> <span class="n">n_epochs</span><span class="p">),</span>
                                        <span class="n">epoch</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">/</span> <span class="n">n_epochs</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">print_loss_avg</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plot_loss_avg</span> <span class="o">=</span> <span class="n">plot_loss_total</span> <span class="o">/</span> <span class="n">plot_every</span>
            <span class="n">plot_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plot_loss_avg</span><span class="p">)</span>
            <span class="n">plot_loss_total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">showPlot</span><span class="p">(</span><span class="n">plot_losses</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">switch_backend</span><span class="p">(</span><span class="s1">'agg'</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="nn">ticker</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">showPlot</span><span class="p">(</span><span class="n">points</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="c1"># this locator puts ticks at regular intervals</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">ticker</span><span class="o">.</span><span class="n">MultipleLocator</span><span class="p">(</span><span class="n">base</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_locator</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>

        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">decoder_attn</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoded_ids</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="n">decoded_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">decoded_ids</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">idx</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">idx</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>
    <span class="k">return</span> <span class="n">decoded_words</span><span class="p">,</span> <span class="n">decoder_attn</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">evaluateRandomly</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">pair</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'&gt;'</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">output_words</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
        <span class="n">output_sentence</span> <span class="o">=</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'&lt;'</span><span class="p">,</span> <span class="n">output_sentence</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">''</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">EncoderRNN</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">AttnDecoderRNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="n">print_every</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">plot_every</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Reading lines...
Read 128133 sentence pairs
Trimmed to 9320 sentence pairs
Counting words...
Counted words:
heb 7519
eng 3067
0m 37s (- 9m 26s) (5 6%) 1.7979
1m 9s (- 8m 6s) (10 12%) 0.9870
1m 41s (- 7m 18s) (15 18%) 0.6160
2m 13s (- 6m 39s) (20 25%) 0.3841
2m 44s (- 6m 2s) (25 31%) 0.2363
3m 16s (- 5m 27s) (30 37%) 0.1482
3m 48s (- 4m 54s) (35 43%) 0.0975
4m 20s (- 4m 20s) (40 50%) 0.0719
4m 52s (- 3m 47s) (45 56%) 0.0569
5m 23s (- 3m 14s) (50 62%) 0.0470
5m 55s (- 2m 41s) (55 68%) 0.0410
6m 27s (- 2m 9s) (60 75%) 0.0363
6m 59s (- 1m 36s) (65 81%) 0.0333
7m 31s (- 1m 4s) (70 87%) 0.0310
8m 2s (- 0m 32s) (75 93%) 0.0286
8m 34s (- 0m 0s) (80 100%) 0.0278
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">evaluateRandomly</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>&gt; הוא בכושר גופני טוב.
= he is in good physical condition
&lt; he is in good physical condition &lt;EOS&gt;

&gt; אני בטוח שתום מתחרט על כך עכשיו.
= i m sure tom regrets that now
&lt; i m sure tom regrets that now &lt;EOS&gt;

&gt; אתה כבר מספיק בוגר כדי לכלכל את עצמך.
= you re now old enough to support yourself
&lt; you are now old enough to support yourself &lt;EOS&gt;

&gt; חזרתי מחופש.
= i m back from vacation
&lt; i m back from vacation &lt;EOS&gt;

&gt; אני בטוחה שתום בדרך.
= i m sure tom is on his way
&lt; tom s sure his custom motorcycle motorcycle their defenseless buried

&gt; אני מוטרדת.
= i m upset
&lt; i m troubled &lt;EOS&gt;

&gt; אני לא מסוגל לתרגם את המשפט הזה.
= i m not able to translate this sentence
&lt; i m unable to translate this sentence &lt;EOS&gt;

&gt; אני מתקומם.
= i m outraged
&lt; i m outraged &lt;EOS&gt;

&gt; הוא אבא לשני ילדים.
= he is the father of two children
&lt; he is the father of two children french fries &lt;EOS&gt;

&gt; הוא פחות או יותר בגילי.
= he is about my age
&lt; he is about my age &lt;EOS&gt;

</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">showAttention</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">,</span> <span class="n">output_words</span><span class="p">,</span> <span class="n">attentions</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">attentions</span><span class="p">):</span>
        <span class="n">attention_data</span> <span class="o">=</span> <span class="n">attentions</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">attention_data</span> <span class="o">=</span> <span class="n">attentions</span>

    <span class="c1"># Flip the attention matrix horizontally for RTL text</span>
    <span class="n">attention_data</span> <span class="o">=</span> <span class="n">attention_data</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">attention_data</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'bone'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>

    <span class="c1"># Reverse the order of input labels for RTL</span>
    <span class="n">input_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">''</span><span class="p">]</span> <span class="o">+</span> <span class="n">input_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">]</span>
    <span class="n">output_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">''</span><span class="p">]</span> <span class="o">+</span> <span class="n">output_words</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_labels</span><span class="p">)))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">input_labels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">output_labels</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">evaluateAndShowAttention</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">output_words</span><span class="p">,</span> <span class="n">attentions</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Input:'</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Output:'</span><span class="p">,</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">))</span>
        <span class="n">showAttention</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">,</span> <span class="n">output_words</span><span class="p">,</span> <span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">output_words</span><span class="p">),</span> <span class="p">:])</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Error occurred: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">evaluateAndShowAttention</span><span class="p">(</span><span class="s1">'אני לא מומחה.'</span><span class="p">)</span>

<span class="n">evaluateAndShowAttention</span><span class="p">(</span><span class="s1">'היא אדם נוח.'</span><span class="p">)</span>

<span class="n">evaluateAndShowAttention</span><span class="p">(</span><span class="s1">'הוא רותח מזעם.'</span><span class="p">)</span>

<span class="n">evaluateAndShowAttention</span><span class="p">(</span><span class="s1">'אתם נמרצים.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Input: אני לא מומחה.
Output: i m not an expert mother &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Input: היא אדם נוח.
Output: she is a pleasant person a rose &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Input: הוא רותח מזעם.
Output: he s outraged something &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Input: אתם נמרצים.
Output: you re energetic &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">nltk.translate.bleu_score</span> <span class="kn">import</span> <span class="n">sentence_bleu</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="nn">ticker</span>

<span class="c1"># Constants</span>
<span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># Data preparation functions</span>
<span class="k">def</span> <span class="nf">get_dataloader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
    <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span><span class="s1">'eng'</span><span class="p">,</span> <span class="s1">'heb'</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">target_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pairs</span><span class="p">):</span>
        <span class="n">inp_ids</span> <span class="o">=</span> <span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
        <span class="n">tgt_ids</span> <span class="o">=</span> <span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span>
        <span class="n">inp_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
        <span class="n">tgt_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
        <span class="n">input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">inp_ids</span><span class="p">)]</span> <span class="o">=</span> <span class="n">inp_ids</span>
        <span class="n">target_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_ids</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tgt_ids</span>

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                              <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

    <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">pairs</span>

<span class="c1"># Model definitions (same as before)</span>
<span class="k">class</span> <span class="nc">ImprovedEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ImprovedEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">hidden_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_p</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reshape_hidden</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">_reshape_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden</span>

<span class="k">class</span> <span class="nc">ScaledDotProductAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ScaledDotProductAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">hidden_size</span><span class="p">]))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>

        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">)</span>

        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">context</span><span class="p">,</span> <span class="n">attention_weights</span>

<span class="k">class</span> <span class="nc">ImprovedDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ImprovedDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">ScaledDotProductAttention</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_p</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">,</span> <span class="n">target_tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">SOS_token</span><span class="p">)</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">attentions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">prev_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">attn_weights</span><span class="p">,</span> <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_step</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">prev_context</span>
            <span class="p">)</span>
            <span class="n">prev_context</span> <span class="o">=</span> <span class="n">context</span>

            <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">)</span>
            <span class="n">attentions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">target_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

                <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">di</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">decoder_input</span><span class="p">):</span>
                    <span class="k">break</span>

        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attentions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attentions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">attentions</span>

    <span class="k">def</span> <span class="nf">forward_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">prev_context</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>

        <span class="n">rnn_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">,</span> <span class="n">prev_context</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">rnn_input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>

        <span class="n">context</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">output</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">attn_weights</span><span class="p">,</span> <span class="n">context</span>

<span class="c1"># Training function</span>
<span class="k">def</span> <span class="nf">train_improved</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                  <span class="n">print_every</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">plot_every</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">plot_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">print_loss_total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">plot_loss_total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">encoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">encoder_scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'min'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">decoder_scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'min'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
            <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">data</span>

            <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
            <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">decoder_outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
                <span class="n">target_tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>

            <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>

        <span class="n">encoder_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>
        <span class="n">decoder_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>

        <span class="n">print_loss_total</span> <span class="o">+=</span> <span class="n">avg_loss</span>
        <span class="n">plot_loss_total</span> <span class="o">+=</span> <span class="n">avg_loss</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">print_loss_avg</span> <span class="o">=</span> <span class="n">print_loss_total</span> <span class="o">/</span> <span class="n">print_every</span>
            <span class="n">print_loss_total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">%s</span><span class="s1"> (</span><span class="si">%d</span><span class="s1"> </span><span class="si">%d%%</span><span class="s1">) </span><span class="si">%.4f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">timeSince</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">/</span> <span class="n">n_epochs</span><span class="p">),</span>
                                        <span class="n">epoch</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">/</span> <span class="n">n_epochs</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">print_loss_avg</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plot_loss_avg</span> <span class="o">=</span> <span class="n">plot_loss_total</span> <span class="o">/</span> <span class="n">plot_every</span>
            <span class="n">plot_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plot_loss_avg</span><span class="p">)</span>
            <span class="n">plot_loss_total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="n">plot_losses</span>

<span class="c1"># Helper function for timing</span>
<span class="k">def</span> <span class="nf">timeSince</span><span class="p">(</span><span class="n">since</span><span class="p">,</span> <span class="n">percent</span><span class="p">):</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">since</span>
    <span class="n">es</span> <span class="o">=</span> <span class="n">s</span> <span class="o">/</span> <span class="p">(</span><span class="n">percent</span><span class="p">)</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">es</span> <span class="o">-</span> <span class="n">s</span>
    <span class="k">return</span> <span class="s1">'</span><span class="si">%s</span><span class="s1"> (- </span><span class="si">%s</span><span class="s1">)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">asMinutes</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">asMinutes</span><span class="p">(</span><span class="n">rs</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">asMinutes</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="n">m</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="s1">'</span><span class="si">%d</span><span class="s1">m </span><span class="si">%d</span><span class="s1">s'</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

<span class="c1"># Main execution</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Get data and create dataloader</span>
    <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

    <span class="c1"># Initialize models</span>
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">improved_encoder</span> <span class="o">=</span> <span class="n">ImprovedEncoder</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">improved_decoder</span> <span class="o">=</span> <span class="n">ImprovedDecoder</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Train the model</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Starting training..."</span><span class="p">)</span>
    <span class="n">improved_losses</span> <span class="o">=</span> <span class="n">train_improved</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">improved_encoder</span><span class="p">,</span> <span class="n">improved_decoder</span><span class="p">,</span>
                                   <span class="n">n_epochs</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">print_every</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">plot_every</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="c1"># Save the trained models</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">improved_encoder</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'improved_encoder.pt'</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">improved_decoder</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'improved_decoder.pt'</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">improved_encoder</span><span class="p">,</span> <span class="n">improved_decoder</span><span class="p">,</span> <span class="n">improved_losses</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="n">improved_encoder</span><span class="p">,</span> <span class="n">improved_decoder</span><span class="p">,</span> <span class="n">improved_losses</span> <span class="o">=</span> <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Reading lines...
Read 128133 sentence pairs
Trimmed to 9320 sentence pairs
Counting words...
Counted words:
heb 7519
eng 3067
Starting training...
0m 42s (- 10m 30s) (5 6%) 1.9305
1m 24s (- 9m 52s) (10 12%) 0.4765
2m 6s (- 9m 9s) (15 18%) 0.1936
2m 48s (- 8m 25s) (20 25%) 0.1238
3m 31s (- 7m 44s) (25 31%) 0.0986
4m 12s (- 7m 1s) (30 37%) 0.0878
4m 54s (- 6m 18s) (35 43%) 0.0786
5m 37s (- 5m 37s) (40 50%) 0.0742
6m 19s (- 4m 54s) (45 56%) 0.0699
7m 0s (- 4m 12s) (50 62%) 0.0675
7m 45s (- 3m 31s) (55 68%) 0.0660
8m 27s (- 2m 49s) (60 75%) 0.0622
9m 9s (- 2m 6s) (65 81%) 0.0613
9m 52s (- 1m 24s) (70 87%) 0.0466
10m 33s (- 0m 42s) (75 93%) 0.0272
11m 15s (- 0m 0s) (80 100%) 0.0247
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Run the training</span>
<span class="n">improved_encoder</span><span class="p">,</span> <span class="n">improved_decoder</span><span class="p">,</span> <span class="n">improved_losses</span> <span class="o">=</span> <span class="n">main</span><span class="p">()</span>

<span class="c1"># After training, you can evaluate some translations</span>
<span class="k">def</span> <span class="nf">evaluate_examples</span><span class="p">():</span>
    <span class="n">improved_encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">improved_decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="n">pair</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Input:'</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Target:'</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">output_words</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">improved_encoder</span><span class="p">,</span> <span class="n">improved_decoder</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
            <span class="n">output_sentence</span> <span class="o">=</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Output:'</span><span class="p">,</span> <span class="n">output_sentence</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>

<span class="n">evaluate_examples</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Reading lines...
Read 128133 sentence pairs
Trimmed to 9320 sentence pairs
Counting words...
Counted words:
heb 7519
eng 3067
Starting training...
0m 42s (- 10m 40s) (5 6%) 1.9347
1m 24s (- 9m 51s) (10 12%) 0.4789
2m 7s (- 9m 10s) (15 18%) 0.1916
2m 50s (- 8m 31s) (20 25%) 0.1222
3m 32s (- 7m 46s) (25 31%) 0.0990
4m 13s (- 7m 2s) (30 37%) 0.0867
4m 56s (- 6m 21s) (35 43%) 0.0800
5m 38s (- 5m 38s) (40 50%) 0.0731
6m 24s (- 4m 59s) (45 56%) 0.0685
7m 6s (- 4m 16s) (50 62%) 0.0524
7m 48s (- 3m 32s) (55 68%) 0.0305
8m 30s (- 2m 50s) (60 75%) 0.0270
9m 12s (- 2m 7s) (65 81%) 0.0253
9m 54s (- 1m 24s) (70 87%) 0.0243
10m 36s (- 0m 42s) (75 93%) 0.0228
11m 19s (- 0m 0s) (80 100%) 0.0225
Input: הוא מתגאה בדייקנות שלו.
Target: he is proud of his punctuality
Output: he is proud of his punctuality &lt;EOS&gt;

Input: אני אמור לאכול עם תום הערב.
Target: i m supposed to eat with tom this evening
Output: i m supposed to eat with tom this evening &lt;EOS&gt;

Input: הוא המורה לאנגלית שלנו.
Target: he is our english teacher
Output: he is our english teacher &lt;EOS&gt;

Input: אני בוגרת מספיק כדי לדאוג לעצמי.
Target: i m old enough to look after myself
Output: i m old enough to look after myself &lt;EOS&gt;

Input: אני רגילה לאכול לבד.
Target: i m used to eating alone
Output: i used used to eating alone alone &lt;EOS&gt;

</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">calculate_metrics</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">test_pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">):</span>
    <span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">total_pairs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_pairs</span><span class="p">)</span>
    <span class="n">exact_matches</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">bleu_total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">test_pairs</span><span class="p">:</span>
            <span class="n">input_sentence</span> <span class="o">=</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">target_sentence</span> <span class="o">=</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># Get model output</span>
            <span class="n">output_words</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
            <span class="n">output_sentence</span> <span class="o">=</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">output_words</span> <span class="k">if</span> <span class="n">word</span> <span class="o">!=</span> <span class="s1">'&lt;EOS&gt;'</span><span class="p">])</span>

            <span class="c1"># Calculate exact match</span>
            <span class="k">if</span> <span class="n">output_sentence</span> <span class="o">==</span> <span class="n">target_sentence</span><span class="p">:</span>
                <span class="n">exact_matches</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Calculate BLEU score</span>
            <span class="n">reference</span> <span class="o">=</span> <span class="p">[</span><span class="n">target_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
            <span class="n">hypothesis</span> <span class="o">=</span> <span class="n">output_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
            <span class="n">bleu_score</span> <span class="o">=</span> <span class="n">sentence_bleu</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">)</span>
            <span class="n">bleu_total</span> <span class="o">+=</span> <span class="n">bleu_score</span>

    <span class="c1"># Calculate metrics</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">exact_matches</span> <span class="o">/</span> <span class="n">total_pairs</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="n">avg_bleu</span> <span class="o">=</span> <span class="p">(</span><span class="n">bleu_total</span> <span class="o">/</span> <span class="n">total_pairs</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Metrics on </span><span class="si">{</span><span class="n">total_pairs</span><span class="si">}</span><span class="s2"> test pairs:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Exact Match Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Average BLEU Score: </span><span class="si">{</span><span class="n">avg_bleu</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">avg_bleu</span>

<span class="c1"># Add this at the end of your main() function:</span>
<span class="n">test_pairs</span> <span class="o">=</span> <span class="n">pairs</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:]</span>  <span class="c1"># Use last 100 pairs as test set</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Evaluating baseline model..."</span><span class="p">)</span>
<span class="n">baseline_accuracy</span><span class="p">,</span> <span class="n">baseline_bleu</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">test_pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Evaluating improved model..."</span><span class="p">)</span>
<span class="n">improved_accuracy</span><span class="p">,</span> <span class="n">improved_bleu</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span><span class="n">improved_encoder</span><span class="p">,</span> <span class="n">improved_decoder</span><span class="p">,</span> <span class="n">test_pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Comparison:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Baseline Model - Accuracy: </span><span class="si">{</span><span class="n">baseline_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, BLEU: </span><span class="si">{</span><span class="n">baseline_bleu</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Improved Model - Accuracy: </span><span class="si">{</span><span class="n">improved_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, BLEU: </span><span class="si">{</span><span class="n">improved_bleu</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Improvement - Accuracy: </span><span class="si">{</span><span class="n">improved_accuracy</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">baseline_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, BLEU: </span><span class="si">{</span><span class="n">improved_bleu</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">baseline_bleu</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
Evaluating baseline model...
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
Metrics on 100 test pairs:
Exact Match Accuracy: 51.00%
Average BLEU Score: 78.69

Evaluating improved model...

Metrics on 100 test pairs:
Exact Match Accuracy: 86.00%
Average BLEU Score: 94.41

Comparison:
Baseline Model - Accuracy: 51.00%, BLEU: 78.69
Improved Model - Accuracy: 86.00%, BLEU: 94.41
Improvement - Accuracy: 35.00%, BLEU: 15.72
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">'/content/drive'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">shell</span>
jupyter nbconvert --to html /content/drive/MyDrive/PS3_Attention_Please_2024_ID_209307396.ipynb
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
